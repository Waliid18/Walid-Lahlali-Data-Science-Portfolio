# Walid Lahlali Data Science Portfolio

Welcome to my **Data Science Portfolio**! This repository is a showcase of the work I’ve completed throughout my data science journey. Organized like a **tree**, this portfolio contains **four** main **directories (branches)**, each filled with projects, assignments, and resources that demonstrate my skills in **data science**, **machine learning**, and **analytics**.

The **four branches** of this **portfolio** are:

**[1.	Bases-Fundamental](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental)**

**[2.	Concordia-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects)**

**[3.	Coursera-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects)**

**[4.	Data-Science-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Data-Science-Projects)**
   
Each branch is divided into subdirectories, and each subdirectory contains **notebooks (leaves)** representing individual projects or assignments. Below is a detailed overview of each branch.

________________________________________


## Repository Structure

**[1. Bases-Fundamental](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental)**
   
This branch focuses on the essential building blocks of data science and Python programming. It contains 11 subdirectories:

   + [Python-Basics-and-Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations): This section introduces the fundamental operations and concepts in Python programming. It includes a series of notebooks that cover topics such as basic data types, arithmetic operations, and string manipulation. Here’s what’s covered:

      + [First Steps in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/1%20-%20First%20steps.ipynb): This notebook covers the very first steps in Python, including basic print statements to display messages like "Hello world" and introducing the user. It demonstrates how to execute simple commands in Python.

      + [Types of Objects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/2%20-%20Types_of_objects.ipynb): This notebook introduces different types of objects in Python such as integers, floats, strings, and booleans. It shows how to create these objects and use the type() function to determine their data type.

      + [The Main Arithmetic Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/3%20-%20The_main_arithmetic_operations.ipynb): This notebook covers the basic arithmetic operations in Python: addition, subtraction, multiplication, and division. It provides examples of each operation using integers, floats, and strings, and explains how the result type varies depending on the input types.

      + [Mathematical Operations with or without Parentheses](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/4%20-%20Mathematical_operations_with_or_without_parentheses.ipynb): This project focuses on performing arithmetic calculations both with and without parentheses to emphasize the order of operations. It demonstrates how parentheses can change the outcome of an expression and covers a variety of arithmetic operations.

      + [Strings in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/5%20-%20Strings.ipynb): This notebook introduces working with strings in Python. It shows how to create strings, access individual characters using indexing, and slice strings. It also includes functions to count the number of characters and print specific portions of the string.

      + [String Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/6%20-%20String%20operations.ipynb): This notebook covers basic string manipulations such as concatenation, repetition, converting strings to uppercase or lowercase, replacing substrings, finding substrings, and splitting strings into lists. It provides hands-on examples of these common string operations.

   + [Python-Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/02%20-%20Python-Lists): This section dives into Python lists, one of the fundamental data structures used to store collections of items. The notebooks cover basic list operations, manipulation techniques, and real-world projects to apply the concepts:
     
      + [Introduction to Python Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/01%20-%20Lists.ipynb): Explores list creation, indexing, modifying elements, and common list operations.
        
      + [Project 1_Managing and Modifying To-Do Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/02%20-%20Project_1_Lists.ipynb): This notebook demonstrates how to create, modify, and manipulate lists. It includes tasks like appending items to a to-do list, accessing specific elements (first, last), modifying elements (replacing "Shopping" with "Museum"), and deleting elements from the list.
        
      + [Project 2_List Manipulation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/03%20-%20Project_2_Lists.ipynb): This project involves working with lists of integers. It covers accessing list elements, modifying values, and using loops to iterate through the list, printing the last element multiple times and creating columns from a list for display.
        
      + [Project 3_Displaying Lists and Counting Multiples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/04%20-%20Project_3_Lists.ipynb): In this notebook, various methods are used to display lists in columns and calculate multiples of numbers in a list. The project includes counting multiples of 3 and 5 in the list and printing the columns of the list in different styles.
        
      + [Project 4_Squaring Elements and Merging Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/05%20-%20Project_4_Lists.ipynb): This project focuses on creating new lists from existing ones. It demonstrates squaring elements in a list and merging two lists (L1 and L2) into new lists (L3 and L4). It also includes checking whether a list is symmetric by comparing elements from both ends.
        
      + [Project 5_Checking Symmetry and Advanced List Manipulations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/06%20-%20Project_5_Lists.ipynb): This notebook continues to explore more advanced list manipulations, including checking if lists are symmetrical (i.e., whether they read the same forward and backward). It also includes operations to merge and manipulate multiple lists.
        
      + [Project 6_User-Defined Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/07%20-%20Project_6_Lists.ipynb): In this notebook, users are prompted to input a list's elements and the length of the list. The project covers how to dynamically create a list based on user input and then print its contents using loops.
        
      + [Project 7_Filtering and Counting Elements in a User-Defined List](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/08%20-%20Project_7_Lists.ipynb): This project focuses on user input to create a list and then filters elements based on a condition. The user is asked to input the number of elements in the list and then provide each element. After displaying the list, the project filters out elements greater than 3, counts them, and displays the count. This project illustrates list creation, input handling, and basic filtering based on conditions.
        
   + [Python-Dictionaries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/03%20-%20Python-Dictionaries): This section provides a comprehensive overview of Python dictionaries and their use in storing key-value pairs. It includes practical projects and exercises to demonstrate dictionary operations, such as adding, updating, and removing elements, as well as more advanced topics like nested dictionaries and dictionary comprehensions:
     
      + [Introduction to Python Dictionaries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/01%20-%20Dictionaries.ipynb): This notebook introduces the basics of Python dictionaries, covering how to create dictionaries, access values using keys, retrieve keys and values, add new key-value pairs, delete entries, and check for the existence of specific keys.
        
      + [Project 1_Tracking Real Madrid's Champions League](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/02%20-%20Project_1_Dictionaries.ipynb): This project focuses on creating a dictionary that stores the years in which Real Madrid won the UEFA Champions League. It includes operations to check if a particular championship year exists in the dictionary and how to display the entire dictionary of wins.
        
      + [Project 2_Managing Product Information](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/03%20-%20Project_2_Dictionaries.ipynb): This notebook demonstrates how to use dictionaries to store product information, including product names, quantities, prices, and release years. It covers adding products to the dictionary, checking for the existence of keys, and deleting specific entries like release years.
        
      + [Project 3_City Profile of Montreal](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/04%20-%20Project_3_Dictionaries.ipynb): In this project, a dictionary is used to store information about the city of Montreal, including its name, country, province, population, and area. The project shows how to update the area, add a new key for population density, and delete and re-add population data.
        
      + [Project 4_Phone Directory Management](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/05%20-%20Project_4_Dictionaries.ipynb): This notebook simulates a phone directory where names are keys and phone numbers are values. It includes retrieving a phone number, checking if a person is in the directory, updating a phone number, adding new contacts, and deleting entries.
        
      + [Project 5_Generating Square Numbers](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/06%20-%20Project_5_Dictionaries.ipynb): This project focuses on creating dictionaries to store square numbers, demonstrating different ways to populate the dictionary. It shows how to define dictionaries directly, manually add key-value pairs, and use a loop to generate squares for a range of numbers.
        
   + [Python-Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/04%20-%20Python-Sets): Operations on Python sets, including union, intersection, and difference:
     
      + [Introduction to Python Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/01%20-%20Sets.ipynb): Learn how to create and manage sets, which automatically remove duplicates, and perform basic operations like union, intersection, and difference.
        
      + [Project 1_Basic Set Operations and Comparisons](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/02%20-%20Project_1_Sets.ipynb): This notebook introduces basic set operations in Python. It demonstrates how to create sets from lists, check for equality between lists and sets, and perform set operations like union, intersection, and difference. It also includes checking for membership in a set, illustrating the use of sets for handling unique values and comparing different collections of data.
        
      + [Project 2_Exploring Unions, Intersections, and Differences with Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/03%20-%20Project_2_Sets.ipynb): This project builds on the basics of sets, showing how to create sets from lists and perform more operations like finding the union and intersection of sets. It also demonstrates how to find unique items between two sets using the difference() method, helping users understand how sets can be used to manage and compare different collections of items.
        
      + [Project 3_Advanced Set Operations: Symmetric Differences and Disjoint Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/04%20-%20Project_3_Sets.ipynb): n this notebook, more advanced set operations are explored. It demonstrates how to compute the symmetric difference of two sets, check whether sets are disjoint, and update sets with the results of symmetric difference and intersection. This project highlights how sets can be used for more complex comparisons and operations, showing their versatility in managing distinct data collections.
        
   + [Python-Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/05%20-%20Python-Loops): Introduction to loops and iteration in Python:

      + [Introduction to Python Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/01%20-%20Loops.ipynb): Covers for loops and while loops, explaining how to iterate through lists and ranges, and how to control loops using break and continue.
      
      + [Project 1_Looping Through Lists and Ranges](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/02%20-%20Project_1_Loops.ipynb): This notebook introduces basic loop structures in Python, including for loops and while loops. It covers examples like iterating through ranges of numbers, looping through a list of sports, iterating over a list of colors, and using a while loop to iterate through playlist ratings and filter color lists.
      
      + [Project 2_ Generating Multiplication Tables Using Nested Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/03%20-%20Project_2_Loops.ipynb): This project focuses on generating multiplication tables from 0 to 12 using nested for loops. It demonstrates how to produce tables in a structured format, showcasing the power of loops for repetitive tasks like generating multiplication tables for educational purposes.
      
      + [Project 3_Creating Number Patterns with Nested Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/04%20-%20Project_3_Loops.ipynb): This notebook demonstrates how to print a pattern of numbers in ascending and descending order using nested loops. It showcases creating a pyramid-like number pattern with increasing and decreasing sequences.
      
      + [Project 4_Filtering Even and Odd Numbers Using Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/05%20-%20Project_4_Loops.ipynb): This project focuses on separating even and odd numbers from a list using a for loop. It demonstrates how to filter elements from a list into two different lists, calculating the count of even and odd numbers.
      
      + [Project 5_Currency Conversion](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/06%20-%20Project_5_Loops.ipynb): This notebook includes converting euros to dollars using a for loop to iterate over a range of values, calculating conversions for different amounts. It shows how to use loops for practical financial calculations like currency conversion.
      
      + [Project 6_Fibonacci Sequence](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/07%20-%20Project_6_Loops.ipynb): This project implements a Fibonacci sequence generator using recursion and for loops. It demonstrates how to calculate and display the first 20 numbers in the Fibonacci sequence, providing insight into recursive function use combined with loops.
      
   + [Python-Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/06%20-%20Python-Functions): Creating and using functions to organize code efficiently. Here’s what’s covered::

      + [Introduction to Python Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/01%20-%20Basic_Functions.ipynb): Covers basic arithmetic and mathematical functions such as addition, subtraction, multiplication, division, square, and square root. It also includes functions to calculate the absolute value, rounding a number, and determining the maximum and minimum of three numbers. These functions are designed for interactive use, taking user input and returning results, which are useful for foundational programming tasks.

      + [Project 1_Basic Arithmetic Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/01%20-%20Basic_Functions.ipynb): Create functions for basic operations like addition, subtraction, multiplication, and division, with error handling for division.

      + [Project 2_Algebraic Identities](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/02%20-%20Project_2_Functions.ipynb): This notebook focuses on algebraic identities, providing functions to compute several remarkable identities. Each function takes input values for the variables and computes the result using the corresponding identity, with the results printed in a structured format. The notebook emphasizes the practical application of algebraic expressions, helping users develop a deeper understanding of mathematical functions and their use in problem-solving.

      + [Project 3_Finding Maximum and Minimum](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/03%20-%20Project_3_Functions.ipynb): In this notebook, the focus is on developing functions to find the maximum and minimum of three numbers. The maximum and minimum functions compare the input values using conditional logic and return the largest or smallest number accordingly. The notebook encourages user interaction by prompting for inputs, providing a hands-on approach to understanding comparison logic and decision-making in Python.

      + [Project 4_Height Traversal Calculation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/04%20-%20Project_4_Functions.ipynb): This notebook contains a function to calculate the total height a person would traverse weekly based on the number of steps and the height of each step. It performs calculations by multiplying the number of steps, step height, and constants, then converting the result into meters. The function includes error handling to ensure only positive inputs are accepted.

      + [Project 5_U.S. Presidential Eligibility Checkers](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/05%20-%20Project_5_Functions.ipynb): This notebook focuses on determining whether a candidate is eligible to run for U.S. presidency based on age. It presents different methods for solving the problem: one using a simple boolean condition, another with if-else logic, and a third method checking both age and natural-born citizenship status. Each function asks for user input to assess a candidate's eligibility.

   + [Pandas-DataFrames](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/07%20-%20Pandas-DataFrames): Working with Pandas DataFrames for data manipulation and analysis. Here’s what’s covered:
     
      + [Introduction to Pandas DataFrames](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/01%20-%20Dataframe.ipynb): Learn how to create, access, and modify DataFrames, and perform essential data operations like sorting, filtering, and aggregating data.
        
      + [Project 1_DataFrame Manipulation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/02%20-%20Project_1_Dataframe.ipynb): This notebook introduces basic DataFrame operations in Python using Pandas. It covers tasks like creating a DataFrame from a dictionary, displaying rows and columns, filtering data, handling missing values, and modifying or updating entries. The project also includes calculating statistical summaries such as the sum of attempts and the mean score, sorting values, and adding or removing columns.
        
      + [Project 2_Student Data Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/03%20-%20Project_2_Dataframe.ipynb): This notebook involves manipulating a DataFrame of student data, focusing on tasks like retrieving specific rows and columns, filtering based on conditions, and calculating statistical summaries (e.g., mean score, total attempts). The notebook showcases different ways to handle data with Pandas, helping to understand filtering, updating, and working with structured data for analysis.
        
      + [Project 3_World Alcohol Consumption](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/04%20-%20Project_3_Dataframe.ipynb): The notebook focuses on analyzing a global beverage consumption dataset, where each row represents a record with the year, country, type of beverage, and average consumption. The analysis includes retrieving information about specific countries, summarizing the average consumption per beverage type, and exploring the distribution of alcohol consumption globally. This project introduces fundamental techniques for working with real-world datasets in the context of global statistics.
        
      + [Project 4_DataFrame Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/05%20-%20Project_4_Dataframe.ipynb): This notebook involves working with a DataFrame by performing various data manipulation tasks, likely similar to those seen in previous projects such as filtering, retrieving, and updating data.
        
      + [Project 5_DataFrame Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/06%20-%20Project_5_Dataframe.ipynb): This project focuses on applying more advanced DataFrame manipulation techniques, building upon previous projects' skills in handling missing data, filtering, and data aggregation. The goal is to refine data analysis techniques, preparing the dataset for deeper statistical exploration.
        
      + [Project 6_Golden State Warriors Data Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/07%20-%20Project_6_DataFrame.ipynb): This project analyzes data related to the Golden State Warriors basketball team, specifically examining matchups against the Toronto Raptors. It includes filtering data for home and away games, calculating statistical summaries like the average PLUS_MINUS and PTS, and visualizing the results over time using Matplotlib.
        
      + [Project 7_Golden State Warriors vs. Toronto Raptors](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/08%20-%20Project_7_DataFrame.ipynb): Similar to Project 6, this notebook also focuses on the performance of the Golden State Warriors in games against the Toronto Raptors. It analyzes home and away games separately, calculating and comparing averages for various metrics. The project includes detailed visualizations of key performance metrics, providing a comprehensive look at how the team performed in different settings.
        
   + [Python-Web-Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/08%20-%20Python-Web-Scraping): Techniques for extracting data from websites using Python libraries. Here’s what’s covered:
     
      + [Introduction to Web Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/08%20-%20Python-Web-Scraping/01%20-%20Web%20Scraping.ipynb): This notebook covers the fundamentals of web scraping using Python libraries such as BeautifulSoup and Requests. It demonstrates how to extract data from HTML structures, including working with elements like tags, attributes, and navigating through a webpage’s structure. The project includes examples like scraping a web page for player salaries, parsing tables with flight and payload data, and retrieving images and links from websites. Additionally, it explores using Pandas to read HTML tables directly from URLs, making it a versatile guide for extracting data from the web for analysis. ​
        
   + [SQL](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/09%20-%20SQL): Basics of database querying and management using SQL.
     
   + [Python-Data-Visualization](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/10%20-%20Python-Data-Visualization): Creating visual representations of data using Python libraries like Matplotlib and Seaborn:
     
      + [Project 1_Immigration to Canada](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/10%20-%20Python-Data-Visualization/01%20-%20Project_1_Data%20Visualization.ipynb): This Data Visualization project explores immigration trends to Canada between 1980 and 2013 using various visualization techniques in Matplotlib. The analysis includes line plots to display trends from countries like Morocco, the UK, and India, as well as area plots for the top five countries with the highest immigration. Additionally, bar and horizontal bar plots are used to visualize immigration data from regions such as Africa and Asia. Through these visualizations, the project provides insights into long-term immigration trends from different countries and continents to Canada.

   + [Machine-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/11%20-%20Machine-Learning): Introduction to fundamental machine learning concepts and algorithms.
     
Each folder contains beginner-level notebooks that cover fundamental steps and key concepts, providing a strong foundation in data science and programming.

________________________________________

**[2. Concordia-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects)**
   
This branch showcases the projects and assignments I completed during my data science certificate at Concordia University. It contains 9 subdirectories, each corresponding to a specific course or project:

   + [Project-Submission](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/00%20-%20Project-Submission): This section contains the final submission for a mini-project, which was part of the admission process to the Data Science program at Concordia University. The project focuses on analyzing football (soccer) data using the Pandas library to answer key statistical questions related to football goals, tournaments, and national performance in FIFA World Cup events. The notebook guides the user through the process of analyzing football match data using Python's Pandas library.
     
   + [Intro-to-Python-and-Math-Fundamentals](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals): This section introduces the essential operations and concepts in Python programming and mathematical foundations. It includes a series of notebooks covering topics such as basic Python syntax, NumPy, statistics, and exploratory data analysis. Here’s what’s covered:
     
      + [Intro to Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/01%20-%20Intro%20to%20Python.ipynb): Covers Python basics, data types, string operations, lists, tuples, and function definitions.
        
      + [Intermediate Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/02%20-%20Intermediate%20Python.ipynb): Explores conditional logic, loops, dictionaries, advanced functions, and error handling.
        
      + [NumPy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/03%20-%20Numpy.ipynb): Introduces array creation, indexing, slicing, reshaping, broadcasting, and statistical operations using NumPy.
        
      + [EDA Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/04%20-%20EDA%20Project.ipynb): Focuses on exploratory data analysis (EDA) using a COVID-19 dataset, examining total cases, deaths, and trends across Canadian provinces.
        
      + [Statistics](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/05%20-%20Statistics.ipynb): Teaches probability, distributions, and hypothesis testing with real-world applications.
        
      + [Web Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/06%20-%20Web%20Scraping.ipynb): Demonstrates web scraping techniques using requests and BeautifulSoup to extract data from websites.
        
   + [Data-Visualization-and-Exploration](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/02%20-%20Data-Visualization-and-Exploration): This section focuses on data visualization and exploration using libraries like Matplotlib and Seaborn. It includes the following notebooks:
     
      + [Matplotlib](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/02%20-%20Data-Visualization-and-Exploration/Notebooks/01%20-%20Matplotlib.ipynb): This notebook demonstrates the use of Matplotlib for creating visualizations, focusing on replicating specific plots. It includes code for plotting and provides guidelines for organizing the code within the same cell to ensure proper output.
        
      + [seaborn Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/02%20-%20Data-Visualization-and-Exploration/Notebooks/02%20-%20seaborn%20Project.ipynb): This project analyzes data from the modern Olympic Games (1896–2016), using Pandas, Seaborn, and Matplotlib for visualization. It explores athlete participation, gender distribution, top medalists, and event trends, highlighting the evolution of the Olympics over time.
        
   + [Algorithms-and-Data-Structures](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures): This section covers fundamental algorithms and data structures, exploring time complexity, object-oriented programming, and practical implementations of sorting and graph traversal. It includes the following notebooks:
     
      + [wkshop_1_min_Big-O Notation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/01%20-%20wkshop_1_min.ipynb): This notebook introduces a class-based implementation in Python, focusing on the creation and manipulation of rational numbers. It walks through the development of a RationalNumber class that supports basic arithmetic operations like addition, subtraction, multiplication, and division on rational numbers. The notebook includes detailed instructions on how to format rational numbers as strings and ensures proper handling of cases like division by zero.
        
      + [wkshop_2_min_Python Classes (Rational Numbers)](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/02%20-%20wkshop_2_min.ipynb): This complete version builds upon the earlier rational number example by refining the operations and including additional functionality. It covers Python concepts such as operator overloading, error handling, and object-oriented design, further enhancing the rational number manipulation class. The notebook also includes testing and examples of how these mathematical operations behave when applied to objects of the custom RationalNumber class.
        
      + [wkshop_2_complete_Linked Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/03%20-%20wkshop_2_complete.ipynb): This notebook introduces linked lists and their operations. It begins with an explanation of the Node class, which represents a single element in a linked list, and includes an exercise to implement this class. The notebook then focuses on reversing a linked list using a function called reverse_ll, which reverses the order of the elements by manipulating the node pointers. The exercises explore the fundamental concepts of linked list structures and provide hands-on practice in implementing and manipulating them in Python.
        
      + [wkshop_3_min_Graphs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/04%20-%20wkshop_3_min.ipynb): This notebook covers graph algorithms, focusing on creating and analyzing simple graphs using the NetworkX library. The first task involves implementing a function, make_simple_graph, which generates a graph based on a given structure and visualizes it. The second task introduces the concept of node degrees, requiring the implementation of a function, compute_degrees, that calculates the degree of each node in the graph. The exercises provide hands-on practice in constructing graphs and analyzing their properties using Python and NetworkX.
        
      + [wkshop_3_complete_Random Walks on Graphs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/05%20-%20wkshop_3_complete.ipynb): This notebook focuses on algorithms for random walks and graph analysis using NetworkX. It begins by implementing a random walk algorithm where the walk starts from a specified node and proceeds for a given number of steps. The notebook then modifies this algorithm to handle weighted graphs, where the probabilities of moving to the next node are based on edge weights. Additionally, there is an exercise to compute the degrees and diameter of a graph without using built-in NetworkX functions, providing a deeper understanding of graph structures and their properties.
        
      + [wkshop_4_min_Recursion and Hybrid Sorting](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/06%20-%20wkshop_4_min.ipynb): This notebook focuses on sorting algorithms and recursion. It begins by implementing a hybrid merge_sort algorithm, which uses selection_sort for sub-arrays smaller than a specified min_size. The exercise compares the performance of this modified merge sort with pure selection sort to analyze their efficiency across different array sizes. Additionally, the notebook introduces an exercise on counting inversions in an array (unsorted pairs), with a hint to modify merge sort to achieve optimal time complexity. This provides hands-on experience in improving algorithm efficiency through hybrid approaches and recursion.
        
   + [SQL-and-PySpark](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/04%20-%20SQL-and-PySpark): This section introduces SQL for database management and PySpark for big data processing, covering fundamental concepts, querying techniques, and distributed data handling. Here’s what’s covered:

      + [wkshop_Data Manipulation and SQLite Queries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/04%20-%20SQL-and-PySpark/Notebook/wkshop.ipynb): This notebook focuses on data manipulation and querying a SQLite database using Pandas. It starts by importing necessary libraries like Pandas, NumPy, Matplotlib, Seaborn, and SQLite. The exercises involve working with the mtcars dataset stored in an SQLite database, where tasks include selecting unique values from a column, creating new columns based on vehicle age, categorizing vehicles into different age groups, and filtering the data based on specific criteria like cylinder count and horsepower.
     
   + [Supervised-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/05%20-%20Supervised-Learning): This section explores supervised machine learning techniques such as regression and classification, covering model development, evaluation metrics, and practical implementations. It includes the following notebooks:

      + [LinearRegression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/01%20-%20LinearRegression.ipynb): This notebook focuses on building and evaluating a Multiple Linear Regression (MLR) model using medical insurance data. It guides through data loading, preparation, and training of a regression model to predict insurance charges. Key tasks include importing necessary libraries, loading the dataset, and performing exploratory data analysis.
        
      + [PolynomialRegression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/02%20-%20PolynomialRegression.ipynb): This notebook extends the analysis from the Linear Regression notebook by applying Polynomial Regression to the same medical insurance dataset. The aim is to predict insurance charges using Polynomial Regression and compare the results with the earlier linear model. The notebook covers data preparation, model training, and evaluation using standard metrics.
        
      + [Regularization](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/03%20-%20Regularization.ipynb): In this notebook, regularization techniques such as Ridge, Lasso, and ElasticNet are applied to the advertising dataset. It focuses on using cross-validation and grid search to tune hyperparameters. The objective is to predict sales based on advertisement spending on TV, radio, and newspapers, with an emphasis on regularized regression models.
        
      + [Statsmodels](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/04%20-%20statsmodels.ipynb): This notebook utilizes the statsmodels library to analyze a dataset containing computer specifications, such as speed, RAM, hard drive size, and price. The goal is to perform exploratory data analysis, including visualizations like histograms and boxplots, and later apply statistical models to predict the price of computers.
        
      + [TimeSeries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/05%20-%20TimeSeries.ipynb): This notebook focuses on time series analysis using baby name frequency data. The tasks involve combining data from multiple files, calculating autocorrelation and partial autocorrelation for selected names, and forecasting future name frequencies using ARIMA models. It covers time series visualization, data splitting, model evaluation, and forecasting for the next two years.
        
      + [LogisticRegression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/06%20-%20LogisticRegression.ipynb): This notebook explores logistic regression using a sonar dataset. The notebook walks through data loading, preparation, and building a logistic regression model. It includes steps for evaluating model performance and predicting outcomes using logistic regression techniques.
        
      + [KNN](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/07%20-%20KNN.ipynb): This notebook focuses on the K-Nearest Neighbors (KNN) algorithm. The data is loaded from the sonar dataset, and the notebook walks through the steps of applying the KNN algorithm to classify data points. The goal is to train, test, and evaluate the KNN model, comparing its performance with other algorithms.
        
      + [SVMs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/08%20-%20SVMs.ipynb): This notebook covers Support Vector Machines (SVMs) and is centered around fraud detection in wine. The dataset contains chemical features of wine samples, and the task is to build a model to detect fraudulent wines. The notebook walks through loading the data, preparing it for analysis, and applying SVMs to classify wines as either "Legit" or "Fraud" based on the given features.
     
   + [Unsupervised-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/06%20-%20Unsupervised-Learning): This section applies unsupervised learning algorithms such as clustering and dimensionality reduction, focusing on data exploration, pattern discovery, and feature extraction. It includes the following notebooks:

      + [KMeans](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/06%20-%20Unsupervised-Learning/Notebooks/01%20-%20KMeans.ipynb): This notebook focuses on K-Means clustering, using a dataset from the CIA World Factbook. The goal is to analyze similarities between countries and regions by experimenting with different numbers of clusters. The notebook includes steps for data loading, scaling, and applying the K-Means algorithm to group countries based on various features.
        
      + [DBSCAN](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/06%20-%20Unsupervised-Learning/Notebooks/02%20-%20DBSCAN.ipynb): This notebook explores the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm using a dataset on wholesale customer annual spending. The goal is to cluster customers based on their spending patterns on various products such as fresh food, milk, groceries, and frozen items. The notebook walks through data loading, scaling, and applying the DBSCAN algorithm to identify meaningful clusters.
     
   + [Deep-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/07%20-%20Deep-Learning): This section introduces deep learning techniques and neural networks, covering model architectures, training methods, and applications in various domains. It includes the following notebooks:

      + [CNNs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/01%20-%20CNNs.ipynb): This notebook is focused on image classification using Convolutional Neural Networks (CNNs). The task is to classify malaria cell images as either "Parasitized" or "Uninfected." The dataset contains over 27,000 images. The notebook includes steps for loading and preprocessing the image data, building the CNN model, and training it to achieve at least 94% accuracy.
        
      + [RNNs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/02%20-%20RNNs.ipynb): This notebook focuses on Recurrent Neural Networks (RNNs), using Canadian cheese production data. It involves building an RNN model using Keras to forecast cheese production for future months. The notebook covers steps such as data preparation, model building, training, and evaluation using mean squared error.
        
      + [Bird Classification Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/03%20-%20Project.ipynb): This notebook focuses on a Bird Classification Project, using the Bird Species dataset from Kaggle. The dataset contains images of 525 bird species, with a goal of building a Convolutional Neural Network (CNN) model that achieves at least 85% accuracy. The notebook outlines the project requirements, including selecting 15 bird species for classification, ensuring consistent species in training, testing, and validation sets, and evaluating the model's performance using the validation set. Tips include using Google Colab for complex models and applying data augmentation to improve performance.
        
      + [NLP](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/04%20-%20NLP.ipynb): This notebook focuses on Natural Language Processing (NLP), specifically scraping app reviews from the Apple Store using a GET API. The task is to predict the 5-star rating for apps based on the review content. The notebook guides through scraping the data, storing it in a DataFrame, and applying various machine learning techniques (such as TF-IDF, logistic regression, and others) to build a predictive model.
     
   + [Final-Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project): This section presents the capstone project, integrating all the skills learned during the certificate. It contains folders with detailed files and requirements that showcase my ability to apply theoretical concepts to practical data science problems. This section is divided as follows:

      + [Proposal](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Proposal): This section introduces the proposal for the Final Capstone Project, detailing the objectives, methodology, and deliverables for analyzing football teams' financial and performance metrics across European leagues. It includes the following accepted proposal file:
         
         + [Final Capstone Project Proposal](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Proposal/Final%20Capstone%20Project%20Proposal.pdf): This PDF represents the proposal of the Final Capstone Project, which has been accepted along with its outlined plan. The project involves an in-depth Exploratory Data Analysis (EDA) of financial and performance metrics for football teams across 15 European leagues. The goal is to explore how financial spending correlates with team performance, identify trends over time, and provide insights through an interactive dashboard. The dataset includes financial information like revenue and spending, and performance data such as goals, wins, and losses. The analysis will help answer key questions about financial efficiency and performance across different leagues.
        
      + [Notebooks](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Notebooks): This section introduces the analysis of financial and performance metrics in European football leagues, covering data collection, cleaning, validation, and exploratory data analysis. It includes the following notebooks:
         
         + [Notebook_1_Data_Collection](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_1_Data_Collection.ipynb): This notebook is the first step in a project analyzing the correlation between financial investment and performance in European football clubs. It focuses on data collection through web scraping from the Transfermarkt website. The target dataset includes financial metrics (revenue, spending, net balance) and performance metrics (goals, wins, losses, league positions) for the top 10 teams from 15 European leagues. The scraped data will form the foundation for further analysis in the project.
           
         + [Notebook_2_Data_Understanding](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_2_Data_Understanding.ipynb): This notebook is dedicated to exploring the collected data to gain insights into its structure and content. It provides an overview of the dataset's features, highlighting numerical and categorical columns, identifying missing values, and detecting duplicates. The notebook sets the stage for further data cleaning and analysis by offering a comprehensive summary of the dataset's current state.
           
         + [Notebook_3_Data_Cleaning_and_Preprocessing](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_3_Data_Cleaning_and_Preprocessing.ipynb): This notebook focuses on cleaning and preprocessing the collected data. It includes steps such as handling missing values, transforming categorical variables, and detecting outliers. The goal is to prepare the dataset for analysis by ensuring it is free of inconsistencies, properly formatted, and ready for further processing in the next stages of the project.
           
         + [Notebook_4_Data_Validation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_4_Data_Validation.ipynb): In this notebook, the cleaned and preprocessed data is validated for accuracy and consistency. The process involves cross-checking for errors, verifying that all necessary transformations were correctly applied, and ensuring that the dataset is suitable for further exploratory data analysis.
           
         + [Notebook_5_Exploratory_Data_Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_5_Exploratory_Data_Analysis.ipynb): This notebook conducts an Exploratory Data Analysis (EDA) to examine financial efficiency and performance metrics in European football leagues. The analysis focuses on how financial spending correlates with team performance, identifying patterns over time, and comparing financial and performance metrics across different leagues. The notebook uses visualizations and descriptive statistics to uncover key insights regarding financial dynamics in European football.
        
      + [Data](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Data): This section introduces the data used for analyzing financial and performance metrics in European football leagues, covering the raw data collection and the final cleaned dataset after preprocessing. It includes the following CSV files:

         + [first_data](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Data/first_data.csv): This file contains the raw data obtained through web scraping from Transfermarkt, capturing financial and performance metrics for 4,342 entries across 15 European football leagues. It includes key columns such as league, team, season, revenue, spent, net, goals for, wins, losses, and position. This dataset represents the initial unprocessed data used for analysis, featuring both financial and performance indicators that will later be cleaned and transformed.
           
         + [clean_data](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Data/clean_data.csv): This file holds the final dataset after completing the cleaning, preprocessing, and validation steps. The data includes 32 columns, with key transformations like log transformations for financial metrics (e.g., log_revenue, log_spent), and performance metrics such as sqrt_goals_for and net_cube_root. New features like winsorized 5-season net and log 5-season relative have been added, providing a refined and structured dataset ready for exploratory analysis.
        
      + [Dashboard](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Dashboard): This section introduces the interactive dashboard used for analyzing financial and performance metrics in European football leagues, built using Streamlit. It includes the following files:
         
         + [app](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Dashboard/app.py): This file contains the code for generating the interactive dashboard. It uses the Streamlit framework to visualize the cleaned data and allow users to explore financial and performance metrics of European football leagues. Running this file will produce the dashboard interface, enabling dynamic analysis of the data.
         
         + [requirements](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Dashboard/requirements.txt): This file lists the dependencies required to run your project, including important libraries such as: numpy, pandas, streamlit, streamlit-option-menu, scikit-learn and matplotlib.
           
         + [clean_data2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Dashboard/clean_data2.csv): This file represents the final cleaned dataset after completing the data cleaning, preprocessing, and validation stages. It is used in the dashboard to present the analysis of financial and performance metrics for European football teams, showcasing the results through interactive visualizations.        
      
      + [Presentation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Presentation): This section introduces the final project presentation, summarizing the objectives, methodology, and key findings from the analysis of football teams' financial and performance metrics across European leagues. It includes the following presentation file: 
         
         + [Final Project Presentation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Presentation/Final%20Project%20Presentation.pdf): This file contains the presentation for your final project titled "Financial Efficiency and Performance Metrics Analysis of European Football Leagues". The presentation covers the project's objectives, methodology, and key findings, highlighting the relationship between financial spending and team performance across various European football leagues. It includes data features such as revenue, spending, net balance, wins, and goals, as well as insights into how financial efficiency impacts team success. The presentation also emphasizes the importance of strategic financial management for long-term stability and success in football.
           
________________________________________


**[3. Coursera-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects)**

This branch highlights the work I’ve done in obtaining multiple data science certifications from Coursera. It contains **6** subdirectories:

   + [Introduction-to-Data-Science-Specialization](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization): This specialization introduced me to the fundamental concepts of data science, including:

      + [Tools-for-Data-Science](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science): This course provides an essential foundation for working with key tools and environments commonly used in data science. Focusing primarily on Jupyter Notebook, the course introduces learners to its interface and core functionalities, including writing and executing code, creating Markdown cells, and handling file operations with Python. Through practical, hands-on exercises, participants gain a solid understanding of how to use Jupyter Notebook for data organization, analysis, and visualization. This course serves as a critical stepping stone for mastering more advanced data science tools and techniques. Here’s what’s covered:
        
         + [Project 1_Getting Started with Jupyter Notebook](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science/Project_1_Getting_Started_with_JupyterNotebook.ipynb): This notebook introduces the basics of using Jupyter Notebook, including creating and executing code and text cells. It covers essential features like inserting images and using Markdown commands to format content.
           
         + [Project 2_Using Markdown](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science/Project_2_Using_markdowns.ipynb): This notebook focuses on using Markdown within Jupyter cells. It teaches how to create headings, bold and italic text, lists, links, and images in notebooks. It also includes practical exercises to manipulate Markdown cells.
           
         + [Project 3_Working with Files](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science/Project_3_Working_with_files.ipynb): This notebook explains how to work with files in a Jupyter environment. It covers reading, writing, and manipulating files using Python, particularly with standard libraries like os and pandas. Practical examples are provided for reading and writing CSV files.
           
      + [Data-Science-Methodology](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/02%20-%20Data-Science-Methodology): This section introduces the key stages of the Data Science Methodology, providing a structured approach to tackling data science projects. It includes a series of notebooks covering topics such as understanding and preparing data, building machine learning models, and evaluating their performance. Here’s what’s covered:
         
         + [Project_1_From Understanding to Preparation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/02%20-%20Data-Science-Methodology/Project_1_From%20Understanding%20to%20Preparation.ipynb): This notebook focuses on understanding the data and preparing it for analysis. It includes steps for exploring and cleaning the dataset, such as handling missing values, formatting data, and performing basic exploratory analysis. The goal is to ensure that the data is in the right format and ready for modeling.
           
         + [Project_2_From Modeling to Evaluation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/02%20-%20Data-Science-Methodology/Project_2_From%20Modeling%20to%20Evaluation.ipynb): This notebook covers the modeling and evaluation phases of the data science methodology. It walks through the process of building machine learning models, training them on the prepared data, and evaluating their performance using metrics like accuracy and confusion matrices. 
           
      + [SQL](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL): This section introduces the essential operations and concepts in SQL for working with databases and performing data analysis. It includes a series of notebooks covering topics such as inserting and updating data in SQLite, using SQL Magic commands in Jupyter, advanced data analysis with SQL queries, and hands-on practice with real-world datasets. Here’s what’s covered:
        
         + [Project_1_Insert_Update_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_1_Insert_Update_SQLite.ipynb): This notebook covers basic SQL operations such as inserting and updating records in a SQLite database. Learners are guided through the process of writing queries to add new data to tables and modify existing data. 
           
         + [Project_2_SQLmagic_SQlite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_2_SQLmagic_SQlite.ipynb): This notebook introduces the use of SQL Magic commands in Jupyter Notebook to interact with SQLite databases. It demonstrates how to run SQL queries directly within the notebook environment using magic commands, providing a convenient way to explore and analyze data.
           
         + [Project_3_Analyzing_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_3_Analyzing_SQLite.ipynb): This notebook focuses on more advanced SQL queries for data analysis. It includes exercises on using aggregate functions, filtering data, and joining tables to extract meaningful insights from datasets.
           
         + [Project_4_RealDataPractice-v5_sqlite_Learner](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_4_RealDataPractice-v5_sqlite_Learner.ipynb): This notebook provides hands-on practice with a real-world dataset using SQLite. Learners are tasked with writing complex SQL queries, using subqueries, and performing data analysis to answer specific business questions. It also covers visualization techniques using Python alongside SQL to better understand the data.
      
   + [IBM-Data-Science-Fundamentals-Python-SQL-Specialization]()

This certificate focuses on Python and SQL skills, featuring:

      + [Tools-for-Data-Science](): Exploration of key tools for data science.
      + [Python-for-Data-Science-AI-and-Development](): In-depth Python programming for data science and AI.
      + [Python-Project-for-Data-Science](): Hands-on project applying Python to solve real-world data problems.
      + [Statistics-for-Data-Science-with-Python](): Key statistical concepts for data analysis.
      + [SQL](): Advanced SQL techniques for database management.
      
   + [IBM-Data-Science-Professional-Certificate]()

A comprehensive program covering the full spectrum of data science skills:

      + [Tools-for-Data-Science]()
      + [Data-Science-Methodology]()
      + [Python-for-Data-Science-AI-and-Development]()
      + [SQL]()
      + [Data-Analysis-with-Python]()
      + [Data-Visualization-with-Python]()
      + [Machine-Learning-with-Python]()
      + [Data-Science-Capstone]()
      
   + [IBM-Data-Analyst-Professional-Certificate]()
     
Focuses on data analysis skills using tools such as Excel, Python, and SQL:

      + [Excel-Basics-for-Data-Analysis]()
      + [Data-Visualization-and-Dashboards-with-Excel-and-Cognos]()
      + [Python-for-Data-Science-AI-and-Development]()
      + [Databases-and-SQL-for-Data-Science-with-Python]()
      + [Data-Analysis-with-Python]()
      + [Data-Analyst-Capstone-Project]()
      
   + [Google-Advanced-Data-Analytics-Professional-Certificate]()

Advanced data analytics and machine learning techniques:

      + [Get-Started-with-Python]()
      + [Go-Beyond-the-Numbers-Translate-Data-into-Insights]()
      + [The-Power-of-Statistics]()
      + [Regression-Analysis-Simplify-Complex-Data-Relationships]()
      + [The-Nuts-and-Bolts-of-Machine-Learning]()
      
   + [Microsoft-Power-BI-Data-Analyst-Professional-Certificate]()

Focused on creating data visualizations and dashboards using Power BI:

      + [Data-Visualization]()
      + [Power-BI-Dashboard-Creation]()
      + [Data Transformation and Cleaning]()
      + [Advanced DAX Functions]()(
      
Each folder contains assignments, practical projects, and case studies from the respective certifications, offering a detailed look at my learning process and practical applications.

________________________________________

**[4. Data-Science-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Data-Science-Projects)**

This branch showcases independent data science projects I’ve worked on, organized into six key categories:

   + Data-Visualization-Projects: Projects focused on creating compelling data visualizations to uncover insights.
   + Exploratory-Data-Analysis-EDA-Projects: Detailed EDA projects that analyze datasets and uncover trends.
   + Machine-Learning-Projects: Machine learning projects ranging from regression and classification to clustering.
   + Natural-Language-Processing-NLP-Projects: Projects focused on NLP techniques such as text classification and sentiment analysis.
   + Deep-Learning-Projects: Projects exploring deep learning techniques, including neural networks and CNNs.
   + Time-Series-Analysis-Projects: Time series analysis and forecasting projects using techniques like ARIMA and LSTM.
     
Each folder contains detailed projects showcasing my ability to apply machine learning, deep learning, and data analysis techniques to real-world data science challenges.

________________________________________

## How to Navigate

   + Branches and Leaves: Each folder (branch) contains subdirectories (branches) and project notebooks (leaves) that represent individual topics, projects, or assignments.
   + Notebooks: Every notebook includes thorough explanations, comments, and code that can be easily followed and reproduced.

________________________________________

## Why This Portfolio?

This portfolio is a reflection of my journey as a data scientist. It demonstrates my expertise across a range of topics, including Python, SQL, machine learning, data visualization, and more. Whether you’re a recruiter looking for a well-rounded candidate or a fellow data scientist looking for inspiration, this portfolio is designed to offer a clear and organized view of my skills and achievements.
Feel free to explore the repository, clone the projects, and reach out if you’d like to discuss further!


