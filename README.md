# Walid Lahlali Data Science Portfolio

Welcome to my **Data Science Portfolio**! This repository is a showcase of the work I’ve completed throughout my data science journey. Organized like a **tree**, this portfolio contains **four** main **directories (branches)**, each filled with projects, assignments, and resources that demonstrate my skills in **data science**, **machine learning**, and **analytics**.

________________________________________

## Table of Contents

1. [Introduction](#introduction)
2. [How to Navigate](#how-to-navigate)
3. [Portfolio Structure](#portfolio-structure)
   
   + Bases-Fundamental
  
   + Concordia-Projects
  
   + Coursera-Projects
  
   + Data-Science-Projects
  
4. [Why This Portfolio?](#why-this-portfolio?)
5. [Key Skills](#key-skills)
6. [Tools and Technologies](#tools-and-technologies)
7. [Contact](#contact)

________________________________________

## Introduction

________________________________________

## How to Navigate

________________________________________

## Portfolio Structure

________________________________________

This portfolio reflects my growth and expertise in data science, highlighting projects across Python, SQL, machine learning, and more. It serves both as a comprehensive record of my journey and as a resource for those interested in data science and advanced analytics.
The **four branches** of this **portfolio** are:

**[1.	Bases-Fundamental](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental)**: This branch houses foundational projects and assignments covering the core principles of Python, statistics, and data manipulation. It provides a strong grounding in essential data science tools and techniques, ideal for building upon in more advanced projects.

**[2.	Concordia-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects)**: This branch includes all my projects and assignments completed during my Data Science Certificate at Concordia University. It contains diverse applications, including data analysis, visualization, machine learning, and project-based work, reflecting both academic rigor and practical applications of data science.

**[3.	Coursera-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects)**: Here, you’ll find work completed across multiple data science certifications on Coursera, including in-depth projects on Python, SQL, statistics, machine learning, and deep learning. This branch emphasizes hands-on projects that develop technical expertise and problem-solving skills in data analytics and machine learning.

**[4.	Data-Science-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Data-Science-Projects)**: This branch showcases independent data science projects I’ve undertaken, spanning various domains and technical topics. Divided into categories like Data Visualization, EDA, Machine Learning, NLP, Deep Learning, and Time Series Analysis, these projects highlight my proficiency in using advanced data science techniques to tackle real-world challenges.
   
Each branch is divided into **subdirectories**, and each subdirectory contains **notebooks (leaves)** representing individual projects or assignments. Below is a detailed overview of each branch.

________________________________________


## Portfolio Structure

**[1. Bases-Fundamental](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental)**
   
This branch focuses on the essential building blocks of data science and Python programming, providing a solid foundation for advanced topics and projects. It contains **11 subdirectories**:

   + [Python-Basics-and-Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations): This section introduces the fundamental operations and concepts in Python programming. It includes a series of notebooks that cover topics such as basic data types, arithmetic operations, and string manipulation. Here’s what’s covered:

      + [First Steps in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/1%20-%20First%20steps.ipynb): This notebook covers the very first steps in Python, including basic print statements to display messages like "Hello world" and introducing the user. It demonstrates how to execute simple commands in Python.

      + [Types of Objects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/2%20-%20Types_of_objects.ipynb): This notebook introduces different types of objects in Python such as integers, floats, strings, and booleans. It shows how to create these objects and use the type() function to determine their data type.

      + [The Main Arithmetic Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/3%20-%20The_main_arithmetic_operations.ipynb): This notebook covers the basic arithmetic operations in Python: addition, subtraction, multiplication, and division. It provides examples of each operation using integers, floats, and strings, and explains how the result type varies depending on the input types.

      + [Mathematical Operations with or without Parentheses](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/4%20-%20Mathematical_operations_with_or_without_parentheses.ipynb): This project focuses on performing arithmetic calculations both with and without parentheses to emphasize the order of operations. It demonstrates how parentheses can change the outcome of an expression and covers a variety of arithmetic operations.

      + [Strings in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/5%20-%20Strings.ipynb): This notebook introduces working with strings in Python. It shows how to create strings, access individual characters using indexing, and slice strings. It also includes functions to count the number of characters and print specific portions of the string.

      + [String Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/01%20-%20Python-Basics-and-Operations/6%20-%20String%20operations.ipynb): This notebook covers basic string manipulations such as concatenation, repetition, converting strings to uppercase or lowercase, replacing substrings, finding substrings, and splitting strings into lists. It provides hands-on examples of these common string operations.

   + [Python-Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/02%20-%20Python-Lists): This section dives into Python lists, one of the fundamental data structures used to store collections of items. The notebooks cover basic list operations, manipulation techniques, and real-world projects to apply the concepts:
     
      + [Introduction to Python Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/01%20-%20Lists.ipynb): Explores list creation, indexing, modifying elements, and common list operations.
        
      + [Project 1_Managing and Modifying To-Do Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/02%20-%20Project_1_Lists.ipynb): This notebook demonstrates how to create, modify, and manipulate lists. It includes tasks like appending items to a to-do list, accessing specific elements (first, last), modifying elements (replacing "Shopping" with "Museum"), and deleting elements from the list.
        
      + [Project 2_List Manipulation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/03%20-%20Project_2_Lists.ipynb): This project involves working with lists of integers. It covers accessing list elements, modifying values, and using loops to iterate through the list, printing the last element multiple times and creating columns from a list for display.
        
      + [Project 3_Displaying Lists and Counting Multiples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/04%20-%20Project_3_Lists.ipynb): In this notebook, various methods are used to display lists in columns and calculate multiples of numbers in a list. The project includes counting multiples of 3 and 5 in the list and printing the columns of the list in different styles.
        
      + [Project 4_Squaring Elements and Merging Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/05%20-%20Project_4_Lists.ipynb): This project focuses on creating new lists from existing ones. It demonstrates squaring elements in a list and merging two lists (L1 and L2) into new lists (L3 and L4). It also includes checking whether a list is symmetric by comparing elements from both ends.
        
      + [Project 5_Checking Symmetry and Advanced List Manipulations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/06%20-%20Project_5_Lists.ipynb): This notebook continues to explore more advanced list manipulations, including checking if lists are symmetrical (i.e., whether they read the same forward and backward). It also includes operations to merge and manipulate multiple lists.
        
      + [Project 6_User-Defined Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/07%20-%20Project_6_Lists.ipynb): In this notebook, users are prompted to input a list's elements and the length of the list. The project covers how to dynamically create a list based on user input and then print its contents using loops.
        
      + [Project 7_Filtering and Counting Elements in a User-Defined List](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/02%20-%20Python-Lists/08%20-%20Project_7_Lists.ipynb): This project focuses on user input to create a list and then filters elements based on a condition. The user is asked to input the number of elements in the list and then provide each element. After displaying the list, the project filters out elements greater than 3, counts them, and displays the count. This project illustrates list creation, input handling, and basic filtering based on conditions.
        
   + [Python-Dictionaries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/03%20-%20Python-Dictionaries): This section provides a comprehensive overview of Python dictionaries and their use in storing key-value pairs. It includes practical projects and exercises to demonstrate dictionary operations, such as adding, updating, and removing elements, as well as more advanced topics like nested dictionaries and dictionary comprehensions:
     
      + [Introduction to Python Dictionaries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/01%20-%20Dictionaries.ipynb): This notebook introduces the basics of Python dictionaries, covering how to create dictionaries, access values using keys, retrieve keys and values, add new key-value pairs, delete entries, and check for the existence of specific keys.
        
      + [Project 1_Tracking Real Madrid's Champions League](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/02%20-%20Project_1_Dictionaries.ipynb): This project focuses on creating a dictionary that stores the years in which Real Madrid won the UEFA Champions League. It includes operations to check if a particular championship year exists in the dictionary and how to display the entire dictionary of wins.
        
      + [Project 2_Managing Product Information](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/03%20-%20Project_2_Dictionaries.ipynb): This notebook demonstrates how to use dictionaries to store product information, including product names, quantities, prices, and release years. It covers adding products to the dictionary, checking for the existence of keys, and deleting specific entries like release years.
        
      + [Project 3_City Profile of Montreal](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/04%20-%20Project_3_Dictionaries.ipynb): In this project, a dictionary is used to store information about the city of Montreal, including its name, country, province, population, and area. The project shows how to update the area, add a new key for population density, and delete and re-add population data.
        
      + [Project 4_Phone Directory Management](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/05%20-%20Project_4_Dictionaries.ipynb): This notebook simulates a phone directory where names are keys and phone numbers are values. It includes retrieving a phone number, checking if a person is in the directory, updating a phone number, adding new contacts, and deleting entries.
        
      + [Project 5_Generating Square Numbers](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/03%20-%20Python-Dictionaries/06%20-%20Project_5_Dictionaries.ipynb): This project focuses on creating dictionaries to store square numbers, demonstrating different ways to populate the dictionary. It shows how to define dictionaries directly, manually add key-value pairs, and use a loop to generate squares for a range of numbers.
        
   + [Python-Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/04%20-%20Python-Sets): Operations on Python sets, including union, intersection, and difference:
     
      + [Introduction to Python Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/01%20-%20Sets.ipynb): Learn how to create and manage sets, which automatically remove duplicates, and perform basic operations like union, intersection, and difference.
        
      + [Project 1_Basic Set Operations and Comparisons](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/02%20-%20Project_1_Sets.ipynb): This notebook introduces basic set operations in Python. It demonstrates how to create sets from lists, check for equality between lists and sets, and perform set operations like union, intersection, and difference. It also includes checking for membership in a set, illustrating the use of sets for handling unique values and comparing different collections of data.
        
      + [Project 2_Exploring Unions, Intersections, and Differences with Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/03%20-%20Project_2_Sets.ipynb): This project builds on the basics of sets, showing how to create sets from lists and perform more operations like finding the union and intersection of sets. It also demonstrates how to find unique items between two sets using the difference() method, helping users understand how sets can be used to manage and compare different collections of items.
        
      + [Project 3_Advanced Set Operations: Symmetric Differences and Disjoint Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/04%20-%20Python-Sets/04%20-%20Project_3_Sets.ipynb): n this notebook, more advanced set operations are explored. It demonstrates how to compute the symmetric difference of two sets, check whether sets are disjoint, and update sets with the results of symmetric difference and intersection. This project highlights how sets can be used for more complex comparisons and operations, showing their versatility in managing distinct data collections.
        
   + [Python-Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/05%20-%20Python-Loops): Introduction to loops and iteration in Python:

      + [Introduction to Python Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/01%20-%20Loops.ipynb): Covers for loops and while loops, explaining how to iterate through lists and ranges, and how to control loops using break and continue.
      
      + [Project 1_Looping Through Lists and Ranges](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/02%20-%20Project_1_Loops.ipynb): This notebook introduces basic loop structures in Python, including for loops and while loops. It covers examples like iterating through ranges of numbers, looping through a list of sports, iterating over a list of colors, and using a while loop to iterate through playlist ratings and filter color lists.
      
      + [Project 2_ Generating Multiplication Tables Using Nested Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/03%20-%20Project_2_Loops.ipynb): This project focuses on generating multiplication tables from 0 to 12 using nested for loops. It demonstrates how to produce tables in a structured format, showcasing the power of loops for repetitive tasks like generating multiplication tables for educational purposes.
      
      + [Project 3_Creating Number Patterns with Nested Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/04%20-%20Project_3_Loops.ipynb): This notebook demonstrates how to print a pattern of numbers in ascending and descending order using nested loops. It showcases creating a pyramid-like number pattern with increasing and decreasing sequences.
      
      + [Project 4_Filtering Even and Odd Numbers Using Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/05%20-%20Project_4_Loops.ipynb): This project focuses on separating even and odd numbers from a list using a for loop. It demonstrates how to filter elements from a list into two different lists, calculating the count of even and odd numbers.
      
      + [Project 5_Currency Conversion](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/06%20-%20Project_5_Loops.ipynb): This notebook includes converting euros to dollars using a for loop to iterate over a range of values, calculating conversions for different amounts. It shows how to use loops for practical financial calculations like currency conversion.
      
      + [Project 6_Fibonacci Sequence](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/05%20-%20Python-Loops/07%20-%20Project_6_Loops.ipynb): This project implements a Fibonacci sequence generator using recursion and for loops. It demonstrates how to calculate and display the first 20 numbers in the Fibonacci sequence, providing insight into recursive function use combined with loops.
      
   + [Python-Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/06%20-%20Python-Functions): Creating and using functions to organize code efficiently. Here’s what’s covered::

      + [Introduction to Python Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/01%20-%20Basic_Functions.ipynb): Covers basic arithmetic and mathematical functions such as addition, subtraction, multiplication, division, square, and square root. It also includes functions to calculate the absolute value, rounding a number, and determining the maximum and minimum of three numbers. These functions are designed for interactive use, taking user input and returning results, which are useful for foundational programming tasks.

      + [Project 1_Basic Arithmetic Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/01%20-%20Basic_Functions.ipynb): Create functions for basic operations like addition, subtraction, multiplication, and division, with error handling for division.

      + [Project 2_Algebraic Identities](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/02%20-%20Project_2_Functions.ipynb): This notebook focuses on algebraic identities, providing functions to compute several remarkable identities. Each function takes input values for the variables and computes the result using the corresponding identity, with the results printed in a structured format. The notebook emphasizes the practical application of algebraic expressions, helping users develop a deeper understanding of mathematical functions and their use in problem-solving.

      + [Project 3_Finding Maximum and Minimum](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/03%20-%20Project_3_Functions.ipynb): In this notebook, the focus is on developing functions to find the maximum and minimum of three numbers. The maximum and minimum functions compare the input values using conditional logic and return the largest or smallest number accordingly. The notebook encourages user interaction by prompting for inputs, providing a hands-on approach to understanding comparison logic and decision-making in Python.

      + [Project 4_Height Traversal Calculation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/04%20-%20Project_4_Functions.ipynb): This notebook contains a function to calculate the total height a person would traverse weekly based on the number of steps and the height of each step. It performs calculations by multiplying the number of steps, step height, and constants, then converting the result into meters. The function includes error handling to ensure only positive inputs are accepted.

      + [Project 5_U.S. Presidential Eligibility Checkers](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/06%20-%20Python-Functions/05%20-%20Project_5_Functions.ipynb): This notebook focuses on determining whether a candidate is eligible to run for U.S. presidency based on age. It presents different methods for solving the problem: one using a simple boolean condition, another with if-else logic, and a third method checking both age and natural-born citizenship status. Each function asks for user input to assess a candidate's eligibility.

   + [Pandas-DataFrames](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/07%20-%20Pandas-DataFrames): Working with Pandas DataFrames for data manipulation and analysis. Here’s what’s covered:
     
      + [Introduction to Pandas DataFrames](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/01%20-%20Dataframe.ipynb): Learn how to create, access, and modify DataFrames, and perform essential data operations like sorting, filtering, and aggregating data.
        
      + [Project 1_DataFrame Manipulation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/02%20-%20Project_1_Dataframe.ipynb): This notebook introduces basic DataFrame operations in Python using Pandas. It covers tasks like creating a DataFrame from a dictionary, displaying rows and columns, filtering data, handling missing values, and modifying or updating entries. The project also includes calculating statistical summaries such as the sum of attempts and the mean score, sorting values, and adding or removing columns.
        
      + [Project 2_Student Data Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/03%20-%20Project_2_Dataframe.ipynb): This notebook involves manipulating a DataFrame of student data, focusing on tasks like retrieving specific rows and columns, filtering based on conditions, and calculating statistical summaries (e.g., mean score, total attempts). The notebook showcases different ways to handle data with Pandas, helping to understand filtering, updating, and working with structured data for analysis.
        
      + [Project 3_World Alcohol Consumption](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/04%20-%20Project_3_Dataframe.ipynb): The notebook focuses on analyzing a global beverage consumption dataset, where each row represents a record with the year, country, type of beverage, and average consumption. The analysis includes retrieving information about specific countries, summarizing the average consumption per beverage type, and exploring the distribution of alcohol consumption globally. This project introduces fundamental techniques for working with real-world datasets in the context of global statistics.
        
      + [Project 4_DataFrame Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/05%20-%20Project_4_Dataframe.ipynb): This notebook involves working with a DataFrame by performing various data manipulation tasks, likely similar to those seen in previous projects such as filtering, retrieving, and updating data.
        
      + [Project 5_DataFrame Operations](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/06%20-%20Project_5_Dataframe.ipynb): This project focuses on applying more advanced DataFrame manipulation techniques, building upon previous projects' skills in handling missing data, filtering, and data aggregation. The goal is to refine data analysis techniques, preparing the dataset for deeper statistical exploration.
        
      + [Project 6_Golden State Warriors Data Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/07%20-%20Project_6_DataFrame.ipynb): This project analyzes data related to the Golden State Warriors basketball team, specifically examining matchups against the Toronto Raptors. It includes filtering data for home and away games, calculating statistical summaries like the average PLUS_MINUS and PTS, and visualizing the results over time using Matplotlib.
        
      + [Project 7_Golden State Warriors vs. Toronto Raptors](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/07%20-%20Pandas-DataFrames/08%20-%20Project_7_DataFrame.ipynb): Similar to Project 6, this notebook also focuses on the performance of the Golden State Warriors in games against the Toronto Raptors. It analyzes home and away games separately, calculating and comparing averages for various metrics. The project includes detailed visualizations of key performance metrics, providing a comprehensive look at how the team performed in different settings.
        
   + [Python-Web-Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/08%20-%20Python-Web-Scraping): Techniques for extracting data from websites using Python libraries. Here’s what’s covered:
     
      + [Introduction to Web Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/08%20-%20Python-Web-Scraping/01%20-%20Web%20Scraping.ipynb): This notebook covers the fundamentals of web scraping using Python libraries such as BeautifulSoup and Requests. It demonstrates how to extract data from HTML structures, including working with elements like tags, attributes, and navigating through a webpage’s structure. The project includes examples like scraping a web page for player salaries, parsing tables with flight and payload data, and retrieving images and links from websites. Additionally, it explores using Pandas to read HTML tables directly from URLs, making it a versatile guide for extracting data from the web for analysis. ​
        
   + [SQL](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/09%20-%20SQL): Basics of database querying and management using SQL.
     
   + [Python-Data-Visualization](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/10%20-%20Python-Data-Visualization): Creating visual representations of data using Python libraries like Matplotlib and Seaborn:
     
      + [Project 1_Immigration to Canada](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Bases-Fundamental/10%20-%20Python-Data-Visualization/01%20-%20Project_1_Data%20Visualization.ipynb): This Data Visualization project explores immigration trends to Canada between 1980 and 2013 using various visualization techniques in Matplotlib. The analysis includes line plots to display trends from countries like Morocco, the UK, and India, as well as area plots for the top five countries with the highest immigration. Additionally, bar and horizontal bar plots are used to visualize immigration data from regions such as Africa and Asia. Through these visualizations, the project provides insights into long-term immigration trends from different countries and continents to Canada.

   + [Machine-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Bases-Fundamental/11%20-%20Machine-Learning): Introduction to fundamental machine learning concepts and algorithms.
     
Each folder contains beginner-level notebooks that cover fundamental steps and key concepts, providing a strong foundation in data science and programming.

________________________________________

**[2. Concordia-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects)**
   
This branch showcases the projects and assignments I completed during my data science certificate at Concordia University. It contains **9 subdirectories**, each corresponding to a specific course or project:

   + [Project-Submission](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/00%20-%20Project-Submission): This section contains the final submission for a mini-project, which was part of the admission process to the Data Science program at Concordia University. The project focuses on analyzing football (soccer) data using the Pandas library to answer key statistical questions related to football goals, tournaments, and national performance in FIFA World Cup events. The notebook guides the user through the process of analyzing football match data using Python's Pandas library.
     
   + [Intro-to-Python-and-Math-Fundamentals](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals): This section introduces the essential operations and concepts in Python programming and mathematical foundations. It includes a series of notebooks covering topics such as basic Python syntax, NumPy, statistics, and exploratory data analysis. Here’s what’s covered:
     
      + [Intro to Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/01%20-%20Intro%20to%20Python.ipynb): Covers Python basics, data types, string operations, lists, tuples, and function definitions.
        
      + [Intermediate Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/02%20-%20Intermediate%20Python.ipynb): Explores conditional logic, loops, dictionaries, advanced functions, and error handling.
        
      + [NumPy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/03%20-%20Numpy.ipynb): Introduces array creation, indexing, slicing, reshaping, broadcasting, and statistical operations using NumPy.
        
      + [EDA Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/04%20-%20EDA%20Project.ipynb): Focuses on exploratory data analysis (EDA) using a COVID-19 dataset, examining total cases, deaths, and trends across Canadian provinces.
        
      + [Statistics](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/05%20-%20Statistics.ipynb): Teaches probability, distributions, and hypothesis testing with real-world applications.
        
      + [Web Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/01%20-%20Intro-to-Python-and-Math-Fundamentals/Notebooks/06%20-%20Web%20Scraping.ipynb): Demonstrates web scraping techniques using requests and BeautifulSoup to extract data from websites.
        
   + [Data-Visualization-and-Exploration](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/02%20-%20Data-Visualization-and-Exploration): This section focuses on data visualization and exploration using libraries like Matplotlib and Seaborn. It includes the following notebooks:
     
      + [Matplotlib](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/02%20-%20Data-Visualization-and-Exploration/Notebooks/01%20-%20Matplotlib.ipynb): This notebook demonstrates the use of Matplotlib for creating visualizations, focusing on replicating specific plots. It includes code for plotting and provides guidelines for organizing the code within the same cell to ensure proper output.
        
      + [seaborn Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/02%20-%20Data-Visualization-and-Exploration/Notebooks/02%20-%20seaborn%20Project.ipynb): This project analyzes data from the modern Olympic Games (1896–2016), using Pandas, Seaborn, and Matplotlib for visualization. It explores athlete participation, gender distribution, top medalists, and event trends, highlighting the evolution of the Olympics over time.
        
   + [Algorithms-and-Data-Structures](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures): This section covers fundamental algorithms and data structures, exploring time complexity, object-oriented programming, and practical implementations of sorting and graph traversal. It includes the following notebooks:
     
      + [wkshop_1_min_Big-O Notation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/01%20-%20wkshop_1_min.ipynb): This notebook introduces a class-based implementation in Python, focusing on the creation and manipulation of rational numbers. It walks through the development of a RationalNumber class that supports basic arithmetic operations like addition, subtraction, multiplication, and division on rational numbers. The notebook includes detailed instructions on how to format rational numbers as strings and ensures proper handling of cases like division by zero.
        
      + [wkshop_2_min_Python Classes (Rational Numbers)](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/02%20-%20wkshop_2_min.ipynb): This complete version builds upon the earlier rational number example by refining the operations and including additional functionality. It covers Python concepts such as operator overloading, error handling, and object-oriented design, further enhancing the rational number manipulation class. The notebook also includes testing and examples of how these mathematical operations behave when applied to objects of the custom RationalNumber class.
        
      + [wkshop_2_complete_Linked Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/03%20-%20wkshop_2_complete.ipynb): This notebook introduces linked lists and their operations. It begins with an explanation of the Node class, which represents a single element in a linked list, and includes an exercise to implement this class. The notebook then focuses on reversing a linked list using a function called reverse_ll, which reverses the order of the elements by manipulating the node pointers. The exercises explore the fundamental concepts of linked list structures and provide hands-on practice in implementing and manipulating them in Python.
        
      + [wkshop_3_min_Graphs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/04%20-%20wkshop_3_min.ipynb): This notebook covers graph algorithms, focusing on creating and analyzing simple graphs using the NetworkX library. The first task involves implementing a function, make_simple_graph, which generates a graph based on a given structure and visualizes it. The second task introduces the concept of node degrees, requiring the implementation of a function, compute_degrees, that calculates the degree of each node in the graph. The exercises provide hands-on practice in constructing graphs and analyzing their properties using Python and NetworkX.
        
      + [wkshop_3_complete_Random Walks on Graphs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/05%20-%20wkshop_3_complete.ipynb): This notebook focuses on algorithms for random walks and graph analysis using NetworkX. It begins by implementing a random walk algorithm where the walk starts from a specified node and proceeds for a given number of steps. The notebook then modifies this algorithm to handle weighted graphs, where the probabilities of moving to the next node are based on edge weights. Additionally, there is an exercise to compute the degrees and diameter of a graph without using built-in NetworkX functions, providing a deeper understanding of graph structures and their properties.
        
      + [wkshop_4_min_Recursion and Hybrid Sorting](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/03%20-%20Algorithms-and-Data-Structures/Notebooks/06%20-%20wkshop_4_min.ipynb): This notebook focuses on sorting algorithms and recursion. It begins by implementing a hybrid merge_sort algorithm, which uses selection_sort for sub-arrays smaller than a specified min_size. The exercise compares the performance of this modified merge sort with pure selection sort to analyze their efficiency across different array sizes. Additionally, the notebook introduces an exercise on counting inversions in an array (unsorted pairs), with a hint to modify merge sort to achieve optimal time complexity. This provides hands-on experience in improving algorithm efficiency through hybrid approaches and recursion.
        
   + [SQL-and-PySpark](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/04%20-%20SQL-and-PySpark): This section introduces SQL for database management and PySpark for big data processing, covering fundamental concepts, querying techniques, and distributed data handling. Here’s what’s covered:

      + [wkshop_Data Manipulation and SQLite Queries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/04%20-%20SQL-and-PySpark/Notebook/wkshop.ipynb): This notebook focuses on data manipulation and querying a SQLite database using Pandas. It starts by importing necessary libraries like Pandas, NumPy, Matplotlib, Seaborn, and SQLite. The exercises involve working with the mtcars dataset stored in an SQLite database, where tasks include selecting unique values from a column, creating new columns based on vehicle age, categorizing vehicles into different age groups, and filtering the data based on specific criteria like cylinder count and horsepower.
     
   + [Supervised-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/05%20-%20Supervised-Learning): This section explores supervised machine learning techniques such as regression and classification, covering model development, evaluation metrics, and practical implementations. It includes the following notebooks:

      + [LinearRegression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/01%20-%20LinearRegression.ipynb): This notebook focuses on building and evaluating a Multiple Linear Regression (MLR) model using medical insurance data. It guides through data loading, preparation, and training of a regression model to predict insurance charges. Key tasks include importing necessary libraries, loading the dataset, and performing exploratory data analysis.
        
      + [PolynomialRegression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/02%20-%20PolynomialRegression.ipynb): This notebook extends the analysis from the Linear Regression notebook by applying Polynomial Regression to the same medical insurance dataset. The aim is to predict insurance charges using Polynomial Regression and compare the results with the earlier linear model. The notebook covers data preparation, model training, and evaluation using standard metrics.
        
      + [Regularization](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/03%20-%20Regularization.ipynb): In this notebook, regularization techniques such as Ridge, Lasso, and ElasticNet are applied to the advertising dataset. It focuses on using cross-validation and grid search to tune hyperparameters. The objective is to predict sales based on advertisement spending on TV, radio, and newspapers, with an emphasis on regularized regression models.
        
      + [Statsmodels](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/04%20-%20statsmodels.ipynb): This notebook utilizes the statsmodels library to analyze a dataset containing computer specifications, such as speed, RAM, hard drive size, and price. The goal is to perform exploratory data analysis, including visualizations like histograms and boxplots, and later apply statistical models to predict the price of computers.
        
      + [TimeSeries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/05%20-%20TimeSeries.ipynb): This notebook focuses on time series analysis using baby name frequency data. The tasks involve combining data from multiple files, calculating autocorrelation and partial autocorrelation for selected names, and forecasting future name frequencies using ARIMA models. It covers time series visualization, data splitting, model evaluation, and forecasting for the next two years.
        
      + [LogisticRegression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/06%20-%20LogisticRegression.ipynb): This notebook explores logistic regression using a sonar dataset. The notebook walks through data loading, preparation, and building a logistic regression model. It includes steps for evaluating model performance and predicting outcomes using logistic regression techniques.
        
      + [KNN](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/07%20-%20KNN.ipynb): This notebook focuses on the K-Nearest Neighbors (KNN) algorithm. The data is loaded from the sonar dataset, and the notebook walks through the steps of applying the KNN algorithm to classify data points. The goal is to train, test, and evaluate the KNN model, comparing its performance with other algorithms.
        
      + [SVMs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/05%20-%20Supervised-Learning/Notebooks/08%20-%20SVMs.ipynb): This notebook covers Support Vector Machines (SVMs) and is centered around fraud detection in wine. The dataset contains chemical features of wine samples, and the task is to build a model to detect fraudulent wines. The notebook walks through loading the data, preparing it for analysis, and applying SVMs to classify wines as either "Legit" or "Fraud" based on the given features.
     
   + [Unsupervised-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/06%20-%20Unsupervised-Learning): This section applies unsupervised learning algorithms such as clustering and dimensionality reduction, focusing on data exploration, pattern discovery, and feature extraction. It includes the following notebooks:

      + [KMeans](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/06%20-%20Unsupervised-Learning/Notebooks/01%20-%20KMeans.ipynb): This notebook focuses on K-Means clustering, using a dataset from the CIA World Factbook. The goal is to analyze similarities between countries and regions by experimenting with different numbers of clusters. The notebook includes steps for data loading, scaling, and applying the K-Means algorithm to group countries based on various features.
        
      + [DBSCAN](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/06%20-%20Unsupervised-Learning/Notebooks/02%20-%20DBSCAN.ipynb): This notebook explores the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm using a dataset on wholesale customer annual spending. The goal is to cluster customers based on their spending patterns on various products such as fresh food, milk, groceries, and frozen items. The notebook walks through data loading, scaling, and applying the DBSCAN algorithm to identify meaningful clusters.
     
   + [Deep-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/07%20-%20Deep-Learning): This section introduces deep learning techniques and neural networks, covering model architectures, training methods, and applications in various domains. It includes the following notebooks:

      + [CNNs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/01%20-%20CNNs.ipynb): This notebook is focused on image classification using Convolutional Neural Networks (CNNs). The task is to classify malaria cell images as either "Parasitized" or "Uninfected." The dataset contains over 27,000 images. The notebook includes steps for loading and preprocessing the image data, building the CNN model, and training it to achieve at least 94% accuracy.
        
      + [RNNs](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/02%20-%20RNNs.ipynb): This notebook focuses on Recurrent Neural Networks (RNNs), using Canadian cheese production data. It involves building an RNN model using Keras to forecast cheese production for future months. The notebook covers steps such as data preparation, model building, training, and evaluation using mean squared error.
        
      + [Bird Classification Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/03%20-%20Project.ipynb): This notebook focuses on a Bird Classification Project, using the Bird Species dataset from Kaggle. The dataset contains images of 525 bird species, with a goal of building a Convolutional Neural Network (CNN) model that achieves at least 85% accuracy. The notebook outlines the project requirements, including selecting 15 bird species for classification, ensuring consistent species in training, testing, and validation sets, and evaluating the model's performance using the validation set. Tips include using Google Colab for complex models and applying data augmentation to improve performance.
        
      + [NLP](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/07%20-%20Deep-Learning/Notebooks/04%20-%20NLP.ipynb): This notebook focuses on Natural Language Processing (NLP), specifically scraping app reviews from the Apple Store using a GET API. The task is to predict the 5-star rating for apps based on the review content. The notebook guides through scraping the data, storing it in a DataFrame, and applying various machine learning techniques (such as TF-IDF, logistic regression, and others) to build a predictive model.
     
   + [Final-Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project): This section presents the capstone project, integrating all the skills learned during the certificate. It contains folders with detailed files and requirements that showcase my ability to apply theoretical concepts to practical data science problems. This section is divided as follows:

      + [Proposal](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Proposal): This section introduces the proposal for the Final Capstone Project, detailing the objectives, methodology, and deliverables for analyzing football teams' financial and performance metrics across European leagues. It includes the following accepted proposal file:
         
         + [Final Capstone Project Proposal](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Proposal/Final%20Capstone%20Project%20Proposal.pdf): This PDF represents the proposal of the Final Capstone Project, which has been accepted along with its outlined plan. The project involves an in-depth Exploratory Data Analysis (EDA) of financial and performance metrics for football teams across 15 European leagues. The goal is to explore how financial spending correlates with team performance, identify trends over time, and provide insights through an interactive dashboard. The dataset includes financial information like revenue and spending, and performance data such as goals, wins, and losses. The analysis will help answer key questions about financial efficiency and performance across different leagues.
        
      + [Notebooks](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Notebooks): This section introduces the analysis of financial and performance metrics in European football leagues, covering data collection, cleaning, validation, and exploratory data analysis. It includes the following notebooks:
         
         + [Notebook_1_Data_Collection](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_1_Data_Collection.ipynb): This notebook is the first step in a project analyzing the correlation between financial investment and performance in European football clubs. It focuses on data collection through web scraping from the Transfermarkt website. The target dataset includes financial metrics (revenue, spending, net balance) and performance metrics (goals, wins, losses, league positions) for the top 10 teams from 15 European leagues. The scraped data will form the foundation for further analysis in the project.
           
         + [Notebook_2_Data_Understanding](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_2_Data_Understanding.ipynb): This notebook is dedicated to exploring the collected data to gain insights into its structure and content. It provides an overview of the dataset's features, highlighting numerical and categorical columns, identifying missing values, and detecting duplicates. The notebook sets the stage for further data cleaning and analysis by offering a comprehensive summary of the dataset's current state.
           
         + [Notebook_3_Data_Cleaning_and_Preprocessing](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_3_Data_Cleaning_and_Preprocessing.ipynb): This notebook focuses on cleaning and preprocessing the collected data. It includes steps such as handling missing values, transforming categorical variables, and detecting outliers. The goal is to prepare the dataset for analysis by ensuring it is free of inconsistencies, properly formatted, and ready for further processing in the next stages of the project.
           
         + [Notebook_4_Data_Validation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_4_Data_Validation.ipynb): In this notebook, the cleaned and preprocessed data is validated for accuracy and consistency. The process involves cross-checking for errors, verifying that all necessary transformations were correctly applied, and ensuring that the dataset is suitable for further exploratory data analysis.
           
         + [Notebook_5_Exploratory_Data_Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Notebooks/Notebook_5_Exploratory_Data_Analysis.ipynb): This notebook conducts an Exploratory Data Analysis (EDA) to examine financial efficiency and performance metrics in European football leagues. The analysis focuses on how financial spending correlates with team performance, identifying patterns over time, and comparing financial and performance metrics across different leagues. The notebook uses visualizations and descriptive statistics to uncover key insights regarding financial dynamics in European football.
        
      + [Data](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Data): This section introduces the data used for analyzing financial and performance metrics in European football leagues, covering the raw data collection and the final cleaned dataset after preprocessing. It includes the following CSV files:

         + [first_data](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Data/first_data.csv): This file contains the raw data obtained through web scraping from Transfermarkt, capturing financial and performance metrics for 4,342 entries across 15 European football leagues. It includes key columns such as league, team, season, revenue, spent, net, goals for, wins, losses, and position. This dataset represents the initial unprocessed data used for analysis, featuring both financial and performance indicators that will later be cleaned and transformed.
           
         + [clean_data](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Data/clean_data.csv): This file holds the final dataset after completing the cleaning, preprocessing, and validation steps. The data includes 32 columns, with key transformations like log transformations for financial metrics (e.g., log_revenue, log_spent), and performance metrics such as sqrt_goals_for and net_cube_root. New features like winsorized 5-season net and log 5-season relative have been added, providing a refined and structured dataset ready for exploratory analysis.
        
      + [Dashboard](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Dashboard): This section introduces the interactive dashboard used for analyzing financial and performance metrics in European football leagues, built using Streamlit. It includes the following files:
         
         + [app](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Dashboard/app.py): This file contains the code for generating the interactive dashboard. It uses the Streamlit framework to visualize the cleaned data and allow users to explore financial and performance metrics of European football leagues. Running this file will produce the dashboard interface, enabling dynamic analysis of the data.
         
         + [requirements](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Dashboard/requirements.txt): This file lists the dependencies required to run your project, including important libraries such as: numpy, pandas, streamlit, streamlit-option-menu, scikit-learn and matplotlib.
           
         + [clean_data2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Dashboard/clean_data2.csv): This file represents the final cleaned dataset after completing the data cleaning, preprocessing, and validation stages. It is used in the dashboard to present the analysis of financial and performance metrics for European football teams, showcasing the results through interactive visualizations.        
      
      + [Presentation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Concordia-Projects/08%20-%20Final-Project/Presentation): This section introduces the final project presentation, summarizing the objectives, methodology, and key findings from the analysis of football teams' financial and performance metrics across European leagues. It includes the following presentation file: 
         
         + [Final Project Presentation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Concordia-Projects/08%20-%20Final-Project/Presentation/Final%20Project%20Presentation.pdf): This file contains the presentation for your final project titled "Financial Efficiency and Performance Metrics Analysis of European Football Leagues". The presentation covers the project's objectives, methodology, and key findings, highlighting the relationship between financial spending and team performance across various European football leagues. It includes data features such as revenue, spending, net balance, wins, and goals, as well as insights into how financial efficiency impacts team success. The presentation also emphasizes the importance of strategic financial management for long-term stability and success in football.
           
________________________________________


**[3. Coursera-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects)**

This branch highlights the extensive work completed while obtaining multiple **data science certifications on Coursera**. It contains **6 subdirectories**, each representing a specific certification or specialization, including:

   + [Introduction-to-Data-Science-Specialization](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization): This specialization certificate introduced me to the fundamental concepts of data science, including:

      + [Tools-for-Data-Science](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science): This course provides an essential foundation for working with key tools and environments commonly used in data science. Focusing primarily on Jupyter Notebook, the course introduces learners to its interface and core functionalities, including writing and executing code, creating Markdown cells, and handling file operations with Python. Through practical, hands-on exercises, participants gain a solid understanding of how to use Jupyter Notebook for data organization, analysis, and visualization. This course serves as a critical stepping stone for mastering more advanced data science tools and techniques. Here’s what’s covered:
        
         + [Project 1_Getting Started with Jupyter Notebook](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science/Project_1_Getting_Started_with_JupyterNotebook.ipynb): This notebook introduces the basics of using Jupyter Notebook, including creating and executing code and text cells. It covers essential features like inserting images and using Markdown commands to format content.
           
         + [Project 2_Using Markdown](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science/Project_2_Using_markdowns.ipynb): This notebook focuses on using Markdown within Jupyter cells. It teaches how to create headings, bold and italic text, lists, links, and images in notebooks. It also includes practical exercises to manipulate Markdown cells.
           
         + [Project 3_Working with Files](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/01%20-%20Tools-for-Data-Science/Project_3_Working_with_files.ipynb): This notebook explains how to work with files in a Jupyter environment. It covers reading, writing, and manipulating files using Python, particularly with standard libraries like os and pandas. Practical examples are provided for reading and writing CSV files.
           
      + [Data-Science-Methodology](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/02%20-%20Data-Science-Methodology): This section introduces the key stages of the Data Science Methodology, providing a structured approach to tackling data science projects. It includes a series of notebooks covering topics such as understanding and preparing data, building machine learning models, and evaluating their performance. Here’s what’s covered:
         
         + [Project_1_From Understanding to Preparation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/02%20-%20Data-Science-Methodology/Project_1_From%20Understanding%20to%20Preparation.ipynb): This notebook focuses on understanding the data and preparing it for analysis. It includes steps for exploring and cleaning the dataset, such as handling missing values, formatting data, and performing basic exploratory analysis. The goal is to ensure that the data is in the right format and ready for modeling.
           
         + [Project_2_From Modeling to Evaluation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/02%20-%20Data-Science-Methodology/Project_2_From%20Modeling%20to%20Evaluation.ipynb): This notebook covers the modeling and evaluation phases of the data science methodology. It walks through the process of building machine learning models, training them on the prepared data, and evaluating their performance using metrics like accuracy and confusion matrices. 
           
      + [SQL](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL): This section introduces the essential operations and concepts in SQL for working with databases and performing data analysis. It includes a series of notebooks covering topics such as inserting and updating data in SQLite, using SQL Magic commands in Jupyter, advanced data analysis with SQL queries, and hands-on practice with real-world datasets. Here’s what’s covered:
        
         + [Project_1_Insert_Update_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_1_Insert_Update_SQLite.ipynb): This notebook covers basic SQL operations such as inserting and updating records in a SQLite database. Learners are guided through the process of writing queries to add new data to tables and modify existing data. 
           
         + [Project_2_SQLmagic_SQlite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_2_SQLmagic_SQlite.ipynb): This notebook introduces the use of SQL Magic commands in Jupyter Notebook to interact with SQLite databases. It demonstrates how to run SQL queries directly within the notebook environment using magic commands, providing a convenient way to explore and analyze data.
           
         + [Project_3_Analyzing_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_3_Analyzing_SQLite.ipynb): This notebook focuses on more advanced SQL queries for data analysis. It includes exercises on using aggregate functions, filtering data, and joining tables to extract meaningful insights from datasets.
           
         + [Project_4_RealDataPractice-v5_sqlite_Learner](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/01%20-%20Introduction-to-Data-Science-Specialization/03%20-%20SQL/Project_4_RealDataPractice-v5_sqlite_Learner.ipynb): This notebook provides hands-on practice with a real-world dataset using SQLite. Learners are tasked with writing complex SQL queries, using subqueries, and performing data analysis to answer specific business questions. It also covers visualization techniques using Python alongside SQL to better understand the data.
      
   + [IBM-Data-Science-Fundamentals-Python-SQL-Specialization](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization) : This certificate provides a strong foundation in key data science tools and techniques, equipping learners with practical skills in data extraction, analysis, and visualization. It also builds proficiency in Python programming, statistical analysis, and database management, including:

      + [Tools-for-Data-Science](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/01-%20Tools-for-Data-Science): This course provides an essential foundation for working with key tools and environments commonly used in data science. Focusing primarily on Jupyter Notebook, the course introduces learners to its interface and core functionalities, including writing and executing code, creating Markdown cells, and handling file operations with Python. Through practical, hands-on exercises, participants gain a solid understanding of how to use Jupyter Notebook for data organization, analysis, and visualization. This course serves as a critical stepping stone for mastering more advanced data science tools and techniques. Here’s what’s covered:
        
         + [Project 1_Getting Started with Jupyter Notebook](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/01-%20Tools-for-Data-Science/Project_1_Getting_Started_with_JupyterNotebook.ipynb): This notebook introduces the basics of using Jupyter Notebook, including creating and executing code and text cells. It covers essential features like inserting images and using Markdown commands to format content.
           
         + [Project 2_Using Markdown](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/01-%20Tools-for-Data-Science/Project_2_Using_markdowns.ipynb): This notebook focuses on using Markdown within Jupyter cells. It teaches how to create headings, bold and italic text, lists, links, and images in notebooks. It also includes practical exercises to manipulate Markdown cells.
           
         + [Project 3_Working with Files](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/01-%20Tools-for-Data-Science/Project_3_Working_with_files.ipynb): This notebook explains how to work with files in a Jupyter environment. It covers reading, writing, and manipulating files using Python, particularly with standard libraries like os and pandas. Practical examples are provided for reading and writing CSV files.
   
      + [Python-for-Data-Science-AI-and-Development](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development): This section introduces the essential operations and concepts in Python programming for data science, AI, and development. It includes a series of notebooks covering topics such as basic Python syntax, data structures (lists, dictionaries, sets), object-oriented programming, file handling, working with NumPy and Pandas, and accessing web data through APIs and web scraping. Here’s what’s covered:
        
         + [Project_01_Types, Expressions, and Variables](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_01_Types%2C%20Expressions%2C%20and%20Variables.ipynb): This notebook covers the basics of Python data types, variable assignments, and expressions. It introduces key concepts like integers, floats, and basic arithmetic operations.
           
         + [Project_02_Strings](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_02_Strings.ipynb): This notebook dives into string manipulation in Python. It covers operations like slicing, concatenation, and string formatting.
           
         + [Project_03_Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_03_Lists.ipynb): This notebook focuses on Python lists, covering essential list operations such as indexing, slicing, appending, and removing elements.

           
         + [Project_04_Tuples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_04_Tuples.ipynb): This notebook introduces Python tuples, explaining their immutable nature and their basic operations like indexing and slicing. 
           
         + [Project_05_Dictionaries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_05_Dictionaries.ipynb): This notebook explains Python dictionaries, covering key-value pairs, accessing, adding, updating, and deleting items in dictionaries, and looping through dictionary elements.
           
         + [Project_06_Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_06_Sets.ipynb): This notebook explores Python sets, discussing their unique element property, and set operations like unions, intersections, and differences.
           
         + [Project_07_Conditions and Branching](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_07_Conditions%20and%20Branching.ipynb): This notebook covers conditional statements (if, else, elif) and logical operators to create decision-making code.
           
         + [Project_08_Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_08_Loops.ipynb): This notebook introduces loops in Python (for and while loops), along with break and continue statements to control the flow of iteration.
           
         + [Project_09_Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_09_Functions.ipynb): This notebook dives into creating and using functions in Python, including passing arguments, returning values, and using default parameters.
           
         + [Project_10_Exception Handling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_10_Exception%20Handling.ipynb): This notebook explains how to handle errors using try, except, and finally blocks to catch and manage exceptions in Python programs.
           
         + [Project_11_Objects and Classes](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_11_Objects%20and%20Classes.ipynb): This notebook introduces Object-Oriented Programming (OOP) concepts in Python, covering how to create and use classes and objects, encapsulation, and method definitions.
           
         + [Project_12_Reading Files with Open](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_12_Reading%20Files%20with%20Open.ipynb): This notebook focuses on reading text files using Python's open() function. It demonstrates various file modes and methods for reading file content, such as read(), readline(), and readlines().
           
         + [Project_13_Writing Files with Open](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_13_Writing%20Files%20with%20Open.ipynb): This notebook teaches how to write data to files using Python's open() function. It covers writing in different modes (write, append) and handling file paths.
           
         + [Project_14_Loading Data with Pandas](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_14_Loading%20Data%20with%20Pandas.ipynb): This notebook introduces the Pandas library for loading and manipulating data. It covers reading data from CSV files, creating DataFrames, and performing basic data operations.
           
         + [Project_15_One Dimensional Numpy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_15_One%20Dimensional%20Numpy.ipynb): This notebook explores one-dimensional arrays in NumPy, including creating, indexing, slicing, and performing basic operations on arrays.
           
         + [Project_16_Two Dimensional Numpy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_16_Two%20Dimensional%20Numpy.ipynb): This notebook expands on NumPy by introducing two-dimensional arrays (matrices), covering indexing, slicing, and performing matrix operations.
           
         + [Project_17_Introduction to API](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_17_Introduction%20to%20API.ipynb): This notebook introduces APIs, explaining how to interact with web services and retrieve data using HTTP requests, primarily using the Python requests library.
           
         + [Project_18_Access REST APIs & Request HTTP](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_18_Access%20REST%20APIs%20%26%20Request%20HTTP.ipynb): This notebook provides practical examples of working with REST APIs, including sending GET and POST requests and handling JSON responses.
           
         + [Project_19_API Examples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_19_API%20Examples.ipynb): This notebook provides examples of accessing different APIs, extracting data, and converting the data into a Pandas DataFrame for analysis.
         
         + [Project_20_Webscraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/02%20-%20Python-for-Data-Science-AI-and-Development/Project_20_Webscraping.ipynb): This notebook covers web scraping techniques using Python’s BeautifulSoup and requests libraries. It demonstrates how to extract data from HTML pages and scrape tabular data using Pandas.
      
      + [Python-Project-for-Data-Science](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/03%20-%20Python-Project-for-Data-Science): This section introduces the practical application of Python programming for data science through a hands-on project. It includes a single notebook that focuses on extracting and visualizing stock data, using tools such as yfinance for financial data extraction, BeautifulSoup for web scraping revenue data, and Plotly for data visualization. Here’s what’s covered:
        
         + [Project_Final Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/03%20-%20Python-Project-for-Data-Science/Project_Final%20Assignment.ipynb): Focuses on extracting and visualizing stock market data using Python. The project involves retrieving Tesla and GameStop stock data using the yfinance library and extracting revenue data through web scraping with BeautifulSoup. A custom function was defined to plot stock data, and Plotly was used to create visualizations of the stock and revenue data for both companies. This assignment demonstrates skills in data extraction, web scraping, and visualization, showcasing practical applications of these techniques in financial data analysis.
           
      + [Statistics-for-Data-Science-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/04%20-%20Statistics-for-Data-Science-with-Python): This section introduces the essential concepts and techniques in statistics for data science using Python. It includes a series of notebooks covering topics such as descriptive statistics, data visualization, probability distributions, hypothesis testing, and regression analysis. These concepts are applied to real-world datasets to help understand data patterns and make informed decisions based on statistical analysis. Here’s what’s covered:
        
         + [Project_01_Descriptive_Statistics](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/04%20-%20Statistics-for-Data-Science-with-Python/Project_01_Descriptive_Statistics.ipynb): This notebook covers the foundational concepts of descriptive statistics, including measures of central tendency (mean, median, mode) and measures of dispersion (variance, standard deviation).
           
         + [Project_02_Visualizing_Data](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/04%20-%20Statistics-for-Data-Science-with-Python/Project_02_Visualizing_Data.ipynb): This notebook introduces various techniques for visualizing data, such as histograms, box plots, and scatter plots, to better understand distributions and relationships between variables.
           
         + [Project_03_Introduction_to_Probability_Distribution](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/04%20-%20Statistics-for-Data-Science-with-Python/Project_03_Introduction_to_Probability_Distribution.ipynb): This notebook explains the fundamentals of probability distributions, including normal, binomial, and Poisson distributions, and demonstrates how to calculate probabilities and use probability density functions.
           
         + [Project_04_Hypothesis_Testing](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/04%20-%20Statistics-for-Data-Science-with-Python/Project_04_Hypothesis_Testing.ipynb): This notebook focuses on hypothesis testing techniques, covering concepts such as null and alternative hypotheses, p-values, t-tests, and chi-square tests for analyzing relationships between variables.
         
         + [Project_05_Regression_Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/04%20-%20Statistics-for-Data-Science-with-Python/Project_05_Regression_Analysis.ipynb): This notebook dives into linear regression analysis, explaining how to build regression models, interpret coefficients, and assess the model’s goodness of fit using R-squared and other statistical metrics.
           
         + [Project_06_Peer_Graded_Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/04%20-%20Statistics-for-Data-Science-with-Python/Project_06_Peer_Graded_Assignment.ipynb): This notebook serves as the final project, applying the concepts learned throughout the course to perform a comprehensive statistical analysis, including hypothesis testing and regression, on real-world data.
      
      + [SQL](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/05%20-%20SQL): This section introduces the essential operations and concepts in SQL for working with databases and performing data analysis. It includes a series of notebooks covering topics such as inserting and updating data in SQLite, using SQL Magic commands in Jupyter, advanced data analysis with SQL queries, and hands-on practice with real-world datasets. Here’s what’s covered:
        
         + [Project_1_Insert_Update_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/05%20-%20SQL/Project_1_Insert_Update_SQLite.ipynb): This notebook covers basic SQL operations such as inserting and updating records in a SQLite database. Learners are guided through the process of writing queries to add new data to tables and modify existing data. 
           
         + [Project_2_SQLmagic_SQlite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/05%20-%20SQL/Project_2_SQLmagic_SQlite.ipynb): This notebook introduces the use of SQL Magic commands in Jupyter Notebook to interact with SQLite databases. It demonstrates how to run SQL queries directly within the notebook environment using magic commands, providing a convenient way to explore and analyze data.
           
         + [Project_3_Analyzing_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/05%20-%20SQL/Project_3_Analyzing_SQLite.ipynb): This notebook focuses on more advanced SQL queries for data analysis. It includes exercises on using aggregate functions, filtering data, and joining tables to extract meaningful insights from datasets.
           
         + [Project_4_RealDataPractice-v5_sqlite_Learner](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/02%20-%20IBM-Data-Science-Fundamentals-Python-SQL-Specialization/05%20-%20SQL/Project_4_RealDataPractice-v5_sqlite_Learner.ipynb): This notebook provides hands-on practice with a real-world dataset using SQLite. Learners are tasked with writing complex SQL queries, using subqueries, and performing data analysis to answer specific business questions. It also covers visualization techniques using Python alongside SQL to better understand the data.
      
   + [IBM-Data-Science-Professional-Certificate](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate): This certificate provides comprehensive training in data science, equipping learners with practical skills across a range of essential tools and techniques. It emphasizes Python programming, SQL, and machine learning, all through hands-on projects. The program fosters proficiency in data analysis, data visualization, and model development, including:
     
      + [Tools-for-Data-Science](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/01-%20Tools-for-Data-Science): This course provides an essential foundation for working with key tools and environments commonly used in data science. Focusing primarily on Jupyter Notebook, the course introduces learners to its interface and core functionalities, including writing and executing code, creating Markdown cells, and handling file operations with Python. Through practical, hands-on exercises, participants gain a solid understanding of how to use Jupyter Notebook for data organization, analysis, and visualization. This course serves as a critical stepping stone for mastering more advanced data science tools and techniques. Here’s what’s covered:
        
         + [Project 1_Getting Started with Jupyter Notebook](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/01-%20Tools-for-Data-Science/Project_1_Getting_Started_with_JupyterNotebook.ipynb): This notebook introduces the basics of using Jupyter Notebook, including creating and executing code and text cells. It covers essential features like inserting images and using Markdown commands to format content.
           
         + [Project 2_Using Markdown](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/01-%20Tools-for-Data-Science/Project_2_Using_markdowns.ipynb): This notebook focuses on using Markdown within Jupyter cells. It teaches how to create headings, bold and italic text, lists, links, and images in notebooks. It also includes practical exercises to manipulate Markdown cells.
           
         + [Project 3_Working with Files](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/01-%20Tools-for-Data-Science/Project_3_Working_with_files.ipynb): This notebook explains how to work with files in a Jupyter environment. It covers reading, writing, and manipulating files using Python, particularly with standard libraries like os and pandas. Practical examples are provided for reading and writing CSV files.
      
      + [Data-Science-Methodology](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/02%20-%20Data-Science-Methodology): This section introduces the key stages of the Data Science Methodology, providing a structured approach to tackling data science projects. It includes a series of notebooks covering topics such as understanding and preparing data, building machine learning models, and evaluating their performance. Here’s what’s covered:
         
         + [Project_1_From Understanding to Preparation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/02%20-%20Data-Science-Methodology/Project_1_From%20Understanding%20to%20Preparation.ipynb): This notebook focuses on understanding the data and preparing it for analysis. It includes steps for exploring and cleaning the dataset, such as handling missing values, formatting data, and performing basic exploratory analysis. The goal is to ensure that the data is in the right format and ready for modeling.
           
         + [Project_2_From Modeling to Evaluation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/02%20-%20Data-Science-Methodology/Project_2_From%20Modeling%20to%20Evaluation.ipynb): This notebook covers the modeling and evaluation phases of the data science methodology. It walks through the process of building machine learning models, training them on the prepared data, and evaluating their performance using metrics like accuracy and confusion matrices. 
      
      + [Python-for-Data-Science-AI-and-Development](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development): This section introduces the essential operations and concepts in Python programming for data science, AI, and development. It includes a series of notebooks covering topics such as basic Python syntax, data structures (lists, dictionaries, sets), object-oriented programming, file handling, working with NumPy and Pandas, and accessing web data through APIs and web scraping. Here’s what’s covered:
        
         + [Project_01_Types, Expressions, and Variables](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_01_Types%2C%20Expressions%2C%20and%20Variables.ipynb): This notebook covers the basics of Python data types, variable assignments, and expressions. It introduces key concepts like integers, floats, and basic arithmetic operations.
           
         + [Project_02_Strings](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_02_Strings.ipynb): This notebook dives into string manipulation in Python. It covers operations like slicing, concatenation, and string formatting.
           
         + [Project_03_Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_03_Lists.ipynb): This notebook focuses on Python lists, covering essential list operations such as indexing, slicing, appending, and removing elements.

           
         + [Project_04_Tuples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_04_Tuples.ipynb): This notebook introduces Python tuples, explaining their immutable nature and their basic operations like indexing and slicing. 
           
         + [Project_05_Dictionaries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_05_Dictionaries.ipynb): This notebook explains Python dictionaries, covering key-value pairs, accessing, adding, updating, and deleting items in dictionaries, and looping through dictionary elements.
           
         + [Project_06_Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_06_Sets.ipynb): This notebook explores Python sets, discussing their unique element property, and set operations like unions, intersections, and differences.
           
         + [Project_07_Conditions and Branching](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_07_Conditions%20and%20Branching.ipynb): This notebook covers conditional statements (if, else, elif) and logical operators to create decision-making code.
           
         + [Project_08_Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_08_Loops.ipynb): This notebook introduces loops in Python (for and while loops), along with break and continue statements to control the flow of iteration.
           
         + [Project_09_Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_09_Functions.ipynb): This notebook dives into creating and using functions in Python, including passing arguments, returning values, and using default parameters.
           
         + [Project_10_Exception Handling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_10_Exception%20Handling.ipynb): This notebook explains how to handle errors using try, except, and finally blocks to catch and manage exceptions in Python programs.
           
         + [Project_11_Objects and Classes](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_11_Objects%20and%20Classes.ipynb): This notebook introduces Object-Oriented Programming (OOP) concepts in Python, covering how to create and use classes and objects, encapsulation, and method definitions.
           
         + [Project_12_Reading Files with Open](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_12_Reading%20Files%20with%20Open.ipynb): This notebook focuses on reading text files using Python's open() function. It demonstrates various file modes and methods for reading file content, such as read(), readline(), and readlines().
           
         + [Project_13_Writing Files with Open](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_13_Writing%20Files%20with%20Open.ipynb): This notebook teaches how to write data to files using Python's open() function. It covers writing in different modes (write, append) and handling file paths.
           
         + [Project_14_Loading Data with Pandas](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_14_Loading%20Data%20with%20Pandas.ipynb): This notebook introduces the Pandas library for loading and manipulating data. It covers reading data from CSV files, creating DataFrames, and performing basic data operations.
           
         + [Project_15_One Dimensional Numpy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_15_One%20Dimensional%20Numpy.ipynb): This notebook explores one-dimensional arrays in NumPy, including creating, indexing, slicing, and performing basic operations on arrays.
           
         + [Project_16_Two Dimensional Numpy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_16_Two%20Dimensional%20Numpy.ipynb): This notebook expands on NumPy by introducing two-dimensional arrays (matrices), covering indexing, slicing, and performing matrix operations.
           
         + [Project_17_Introduction to API](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_17_Introduction%20to%20API.ipynb): This notebook introduces APIs, explaining how to interact with web services and retrieve data using HTTP requests, primarily using the Python requests library.
           
         + [Project_18_Access REST APIs & Request HTTP](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_18_Access%20REST%20APIs%20%26%20Request%20HTTP.ipynb): This notebook provides practical examples of working with REST APIs, including sending GET and POST requests and handling JSON responses.
           
         + [Project_19_API Examples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_19_API%20Examples.ipynb): This notebook provides examples of accessing different APIs, extracting data, and converting the data into a Pandas DataFrame for analysis.
         
         + [Project_20_Webscraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_20_Webscraping.ipynb): This notebook covers web scraping techniques using Python’s BeautifulSoup and requests libraries. It demonstrates how to extract data from HTML pages and scrape tabular data using Pandas.
      
      + [SQL](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/04%20-%20SQL): This section introduces the essential operations and concepts in SQL for working with databases and performing data analysis. It includes a series of notebooks covering topics such as inserting and updating data in SQLite, using SQL Magic commands in Jupyter, advanced data analysis with SQL queries, and hands-on practice with real-world datasets. Here’s what’s covered:
        
         + [Project_1_Insert_Update_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/04%20-%20SQL/Project_1_Insert_Update_SQLite.ipynb): This notebook covers basic SQL operations such as inserting and updating records in a SQLite database. Learners are guided through the process of writing queries to add new data to tables and modify existing data. 
           
         + [Project_2_SQLmagic_SQlite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/04%20-%20SQL/Project_2_SQLmagic_SQlite.ipynb): This notebook introduces the use of SQL Magic commands in Jupyter Notebook to interact with SQLite databases. It demonstrates how to run SQL queries directly within the notebook environment using magic commands, providing a convenient way to explore and analyze data.
           
         + [Project_3_Analyzing_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/04%20-%20SQL/Project_3_Analyzing_SQLite.ipynb): This notebook focuses on more advanced SQL queries for data analysis. It includes exercises on using aggregate functions, filtering data, and joining tables to extract meaningful insights from datasets.
           
         + [Project_4_RealDataPractice-v5_sqlite_Learner](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/04%20-%20SQL/Project_4_RealDataPractice-v5_sqlite_Learner.ipynb): This notebook provides hands-on practice with a real-world dataset using SQLite. Learners are tasked with writing complex SQL queries, using subqueries, and performing data analysis to answer specific business questions. It also covers visualization techniques using Python alongside SQL to better understand the data.
      
      + [Data-Analysis-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python): This section provides a comprehensive introduction to data analysis using Python. It includes a series of notebooks covering essential topics such as data wrangling, visualization, regression models, and machine learning techniques. The projects focus on manipulating datasets using libraries like Pandas and NumPy, performing exploratory data analysis, and building predictive models. Here’s what’s covered:

         + [Project_01_Introduction](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_01_Introduction.ipynb): This notebook introduces basic data acquisition techniques, demonstrating how to load datasets into Python using Pandas. The example dataset used is related to automobiles, and the notebook covers how to gain basic insights through descriptive statistics.
       
         + [Project_02_Practice data loading](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_02_Practice%20data%20loading.ipynb): Focuses on practicing data loading techniques using a laptop pricing dataset. The notebook demonstrates importing CSV files into Pandas and explores basic data cleaning, such as handling missing values and checking data types.
       
         + [Project_03_Review Data Wrangling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_03_Review%20Data%20Wrangling.ipynb): Covers essential data wrangling techniques, including identifying and handling missing values, converting data types, and generating indicator variables. The notebook prepares the dataset for further analysis through cleaning and transformation.
       
         + [Project_04_Practice datawrangling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_04_Practice%20datawrangling.ipynb): Provides hands-on practice in cleaning and transforming data, covering tasks such as handling missing values, standardizing and normalizing features, and converting categorical variables into numerical indicators, with visualizations of binned data.
       
         + [Project_05_Exploratory data analysis cars](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_05_Exploratory%20data%20analysis%20cars.ipynb): This notebook performs exploratory data analysis on a car dataset. It explores correlations between various numerical and categorical features and price, using regression plots and boxplots to identify key variables for future modeling.
       
         + [Project_06_Parctice Exploratory data analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_06_Parctice%20Exploratory%20data%20analysis.ipynb): Focuses on analyzing the relationship between laptop features and prices. The notebook covers visualizing feature distributions, performing descriptive statistical analysis, and calculating Pearson correlation to identify important predictors.
       
         + [Project_07_Review Model Development](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_07_Review%20Model%20Development.ipynb): This notebook explores different regression models, including simple and multiple linear regression, as well as polynomial regression. It compares models using metrics such as MSE and R², concluding that multiple linear regression provides the best fit for predicting car prices.
       
         + [Project_08_Practice Model Development Laptops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_08_Practice%20Model%20Development%20Laptops.ipynb): Demonstrates building predictive models for laptop prices using simple, multiple, and polynomial regression. A pipeline is used for scaling, transforming, and fitting the model, with model performance evaluated based on R² and MSE.
       
         + [Project_09_Model Evaluation and Refinement cars](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_09_Model%20Evaluation%20and%20Refinement%20cars.ipynb): This notebook focuses on evaluating regression models using cross-validation and refining them with Ridge regression to prevent overfitting. The best model is selected by tuning hyperparameters and assessing performance with R² and MSE.
       
         + [Project_10_Practice Model Evaluation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_10_Practice%20Model%20Evaluation.ipynb): Evaluates and refines laptop price prediction models through cross-validation, Ridge regression, and hyperparameter tuning using Grid Search. The notebook focuses on improving model performance by selecting optimal hyperparameters and testing on unseen data.
       
         + [Project_11_House Sales in King Count USA](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/05%20-%20Data-Analysis-with-Python/Project_11_House%20Sales%20in%20King%20Count%20USA.ipynb): In this project, the objective is to predict house prices in King County, USA, using various features such as square footage, number of bedrooms, and floors. The notebook covers essential steps including data wrangling, exploratory data analysis, and the development of regression models to estimate housing prices. The final phase involves evaluating and refining the models to enhance predictive accuracy, making this project a comprehensive exploration of real estate data analytics.
      
      + [Data-Visualization-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python): This section introduces essential concepts and techniques for data visualization using Python. It includes a series of notebooks covering topics such as creating visualizations with Matplotlib, generating advanced plots like waffle charts and word clouds, and mapping geospatial data with Folium. These projects focus on effectively visualizing data to uncover insights. Here’s what’s covered:
    
         + [Project_1_Dataset Preprocessing Exploring with Pandas](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_1_Dataset%20Preprocessing%20Exploring%20with%20Pandas.ipynb): This notebook serves as a refresher on using the Pandas library for data exploration and preprocessing. It covers essential techniques for wrangling data, including sorting, filtering, and selecting data based on conditions. The example dataset used focuses on immigration to Canada from 1980 to 2013. This project provides a foundation for preparing datasets before applying data visualization techniques.
    
         + [Project_2_Introduction to Matplotlib and Line Plots](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_2_Introduction%20to%20Matplotlib%20and%20Line%20Plots.ipynb): This notebook introduces the basics of data visualization using the Matplotlib library. It focuses on creating line plots to visualize trends in data, specifically using the example of immigration to Canada from 1980 to 2013. The notebook covers essential plotting techniques and provides insights on customizing plots, making it a useful starting point for anyone learning how to visualize data with Matplotlib.
    
         + [Project_3_Pie Charts Box Plots Scatter Plots and Bubble Plots](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_3_Pie%20Charts%20Box%20Plots%20Scatter%20Plots%20and%20Bubble%20Plots.ipynb): This notebook introduces various data visualization techniques using Matplotlib, including pie charts, box plots, scatter plots, and bubble plots. These visualizations are useful for displaying data distributions, identifying outliers, and comparing multiple variables. The notebook explores different plotting methods, with a focus on interpreting data effectively through visual representations. It uses an example dataset on immigration to Canada from 1980 to 2013.
    
         + [Project_4_Plotting directly with Matplotlib](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_4_Plotting%20directly%20with%20Matplotlib.ipynb): This notebook provides a hands-on introduction to plotting directly using Matplotlib. It covers key concepts such as customizing plots with markers, colors, and line styles, as well as creating subplots to display multiple visualizations simultaneously. The example dataset focuses on visualizing immigration data to Canada from 1980 to 2013. Additionally, the notebook demonstrates how to fine-tune plot aesthetics, including grid lines, legends, axis limits, and titles.
    
         + [Project_5_Waffle Charts Word Clouds and Regression Plots](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_5_Waffle%20Charts%20Word%20Clouds%20and%20Regression%20Plots.ipynb): This notebook explores advanced visualization techniques, including waffle charts, word clouds, and regression plots. Using the Matplotlib and PyWaffle libraries, the notebook demonstrates how to create waffle charts to show proportions of categories, generate word clouds for text-based data visualization, and use Seaborn to produce regression plots that highlight trends and relationships between variables. The example dataset focuses on immigration to Canada from 1980 to 2013.
    
         + [Project_6_Creating maps visualizing geospat](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_6_Creating%20maps%20visualizing%20geospat.ipynb): This notebook focuses on geospatial data visualization using the Folium library. It introduces how to create various types of maps, including choropleth maps, to visualize data on a geographical scale. Using immigration data to Canada from 1980 to 2013, the notebook demonstrates how to generate maps that represent the total number of immigrants from different countries. This project showcases how to effectively combine data analysis and mapping techniques to reveal spatial trends.
    
         + [Project_7_Practice_Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_7_Practice_Assignment.ipynb): This notebook focuses on visualizing and analyzing wildfire activities in Australia. It uses libraries like Pandas, Seaborn, and Folium to create informative plots and charts. The project guides users through tasks involving geospatial data mapping, where markers represent different regions of Australia. It also demonstrates how to plot the geographical locations of wildfires on a map using Folium, providing a practical application of data visualization for disaster analysis.
    
         + [Project_8_Final Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/06%20-%20Data-Visualization-with-Python/Project_8_Final%20Assignment.ipynb): This notebook guides users through a comprehensive analysis of automobile sales during recession periods. It demonstrates how to create visualizations using libraries such as Seaborn and Folium. The analysis covers vehicle-wise sales during recession and non-recession periods and includes tasks such as generating bar charts and choropleth maps to show the geographical impact of recessions on automobile sales. This final project provides a hands-on approach to combining data analysis and visualization techniques to gain insights from real-world data.
      
      + [Machine-Learning-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python): This section provides a comprehensive introduction to machine learning concepts and techniques using Python. It includes a series of projects that cover essential topics such as linear regression, classification algorithms, clustering, and model evaluation. The projects explore real-world applications of machine learning, including regression models, decision trees, K-means clustering, and support vector machines, providing hands-on experience in building and assessing predictive models. Here’s what’s covered:
    
         + [Project_01_Simple Linear Regression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_01_Simple%20Linear%20Regression.ipynb): This notebook introduces simple linear regression using the scikit-learn library. The project focuses on creating a model, training it, testing it, and using the model for prediction. The dataset used involves fuel consumption ratings and carbon dioxide emissions for vehicles in Canada. Key tasks include data downloading, exploration, and model implementation to predict emissions based on engine size.
       
         + [Project_02_Mulitple Linear Regression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_02_Mulitple%20Linear%20Regression.ipynb): This notebook covers multiple linear regression using the scikit-learn library. It guides through the process of creating, training, and testing a model that predicts carbon dioxide emissions based on multiple features such as engine size, fuel consumption, and others. The project provides a hands-on approach to understanding and applying multiple regression for real-world predictions using a vehicle emissions dataset.
       
         + [Project_03_K-Nearest neighbors](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_03_K-Nearest%20neighbors.ipynb): This notebook introduces the K-Nearest Neighbors (KNN) algorithm for classification. The project demonstrates how to load a dataset, train a KNN model, and use it to predict classifications. It covers the importance of choosing the right value of K and shows the impact of different values on prediction results. The dataset used is a customer dataset, and the model classifies customers based on various features.
       
         + [Project_04_Decision Trees](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_04_Decision%20Trees.ipynb): This notebook introduces the Decision Tree classification algorithm. The project focuses on building a decision tree model using a dataset of patient responses to various medications. The model is trained to predict the appropriate medication for new patients. Key tasks include downloading and preparing the dataset, setting up the decision tree, making predictions, and evaluating the model's performance. The project also includes visualizing the decision tree for better understanding.
       
         + [Project_05_Regression Trees](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_05_Regression%20Trees.ipynb): This notebook introduces regression trees using the scikit-learn library. The project focuses on training and evaluating a regression tree model to predict the median price of houses in different areas of Boston. The notebook covers the steps of splitting the data, training the model, and assessing its performance using R² values and mean absolute error. It also includes exercises to apply different evaluation criteria and compare the results.
       
         + [Project_06_Logistic Regression](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_06_Logistic%20Regression.ipynb): This notebook introduces logistic regression for classification using the scikit-learn library. The project involves building a model for a telecommunication company to predict customer churn, i.e., whether customers will leave for a competitor. The notebook covers data preprocessing, model training, evaluation using a confusion matrix, and understanding the difference between logistic and linear regression.
       
         + [Project_07_SVM](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_07_SVM.ipynb): This notebook introduces the Support Vector Machine (SVM) algorithm for classification. The project involves using SVM to build a model that classifies human cell records as either benign or malignant. The notebook covers loading the dataset, training the SVM model, and evaluating its performance using metrics such as accuracy, F1-score, and Jaccard index. The project highlights the power of SVM in handling non-linearly separable data by finding an optimal hyperplane.
       
         + [Project_08_Multi-class Classification](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_08_Multi-class%20Classification.ipynb): This notebook explores multi-class classification techniques, including softmax regression (multinomial logistic regression), One-vs-All (One-vs-Rest), and One-vs-One methods. The project demonstrates how to convert binary classifiers into multi-class classifiers, allowing for the classification of data into multiple class labels. It includes hands-on practice with various datasets and evaluates model performance using accuracy metrics.
       
         + [Project_09_Clusters K-Means](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_09_Clusters%20K-Means.ipynb): This notebook introduces the K-Means clustering algorithm using scikit-learn. The project involves two key examples: clustering a randomly generated dataset and applying K-Means for customer segmentation. It demonstrates how K-Means can be used to discover patterns in unlabeled data and includes visualizations to understand the clusters. Real-world applications of K-Means include customer segmentation, pattern recognition, and data compression.
       
         + [Project_10_Final Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/07%20-%20Machine-Learning-with-Python/Project_10_Final%20Assignment.ipynb): This notebook serves as the final project for classification algorithms. It brings together all the classification techniques learned throughout the course, including Linear Regression, K-Nearest Neighbors (KNN), Decision Trees, Logistic Regression, and Support Vector Machines (SVM). The project focuses on training and testing these models using various evaluation metrics such as accuracy score, Jaccard index, F1-score, and LogLoss. It provides a comprehensive review and practical application of these classification methods.
      
      + [Data-Science-Capstone](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone): This section provides a comprehensive overview of advanced data science concepts and methodologies. It includes a series of projects covering topics such as data collection via APIs and web scraping, data wrangling, SQL queries, and machine learning model development. The projects focus on real-world applications, including predicting SpaceX Falcon 9 first stage landings and analyzing launch site performance. Here’s what’s covered:
    
         + [Project_1_SpaceX Data Collection API](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/Project_1_SpaceX%20Data%20Collection%20API.ipynb): This notebook focuses on collecting data from the SpaceX API. The project involves making requests to the API to retrieve data on Falcon 9 launches and performing basic data wrangling. It covers retrieving launch details, cleaning the data, and handling missing values. The dataset is then prepared for further analysis by saving it in CSV format. The goal is to collect and format the data for use in predicting Falcon 9 first stage landing success.
       
         + [Project_2_WebScraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/Project_2_WebScraping.ipynb): This notebook focuses on web scraping to collect historical launch records of Falcon 9 and Falcon Heavy rockets from a Wikipedia page. The project involves extracting a specific HTML table containing launch data, parsing it using BeautifulSoup, and converting the extracted data into a Pandas DataFrame. The cleaned data is then saved as a CSV file for further analysis. This project demonstrates how to automate data collection from web pages for use in predictive modeling.
       
         + [Project_3_SpaceX Data Wrangling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/Project_3_SpaceX%20Data%20Wrangling.ipynb): This notebook focuses on data wrangling to prepare the SpaceX Falcon 9 launch data for machine learning models. The project involves cleaning and organizing the dataset, handling missing values, and generating new features. Key tasks include converting mission outcomes into binary labels (successful or unsuccessful landings), performing exploratory data analysis (EDA), and exporting the cleaned dataset for use in predictive modeling. The project ensures that the data is ready for further analysis and machine learning.
       
         + [Project_4_SQL](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/Project_4_SQL.ipynb): This notebook demonstrates how to use SQL to analyze the SpaceX dataset. The project involves loading the dataset into a SQL database and executing various queries to explore SpaceX mission data. Key tasks include retrieving information on launch outcomes, payloads, and landing success rates. The notebook shows how SQL can be used to derive meaningful insights from structured data, supporting decision-making in the space industry.
       
         + [Project_5_Launch Site Location](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/Project_5_Launch%20Site%20Location.ipynb): This notebook explores the geographical distribution of SpaceX launch sites using the Folium library for interactive maps. The project involves marking all launch sites on a map, visualizing successful and failed launches, and calculating distances between launch sites and key proximities, such as coastlines and cities. The objective is to analyze whether launch site locations play a role in the success of Falcon 9 launches and discover geographical patterns that could influence future site selection.
       
         + [Project_6_SpaceXMachine Learning Prediction](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/Project_6_SpaceXMachine%20Learning%20Prediction.ipynb): This notebook focuses on building a machine learning pipeline to predict the success of Falcon 9 first stage landings. The project involves performing exploratory data analysis, preparing the dataset by standardizing and splitting the data, and training various models such as Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Decision Trees, and Logistic Regression. The notebook also includes hyperparameter tuning using GridSearchCV and evaluates the models to determine the best-performing one for predicting landing success.
       
         + [Space Y - Presentation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/Space%20Y%20-%20Presentation.pdf): This presentation explores the evolution of space exploration and the rise of commercial space travel. It highlights the achievements of companies like SpaceX, Virgin Galactic, and Rocket Lab, with a special focus on SpaceX's innovations in reducing the cost of launches through reusability. The presentation introduces Space Y, a new contender in the space industry, and discusses how predictive analytics, data wrangling, and machine learning can help forecast launch costs and first-stage reusability. Through detailed data analysis, Space Y aims to rival SpaceX's dominance in the space industry, leveraging data-driven decision-making to optimize performance and costs in space missions.
       
         + [README](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/03%20-%20IBM-Data-Science-Professional-Certificate/08%20-%20Data-Science-Capstone/README.md): This README provides a detailed overview of the Data Science Capstone project, outlining the key topics, methodologies, and data science techniques used throughout the project. It includes descriptions of the data collection, processing, and analysis steps, along with insights from predictive modeling and machine learning applications.
      
   + [IBM-Data-Analyst-Professional-Certificate](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate): This certification provided a comprehensive foundation in data analysis, covering essential skills in Excel, Python, SQL, and data visualization techniques. Through a series of hands-on projects, I gained practical experience in manipulating data, performing exploratory data analysis, creating visualizations, and building dashboards. Key topics include:

      + [Excel-Basics-for-Data-Analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/01%20-%20Excel-Basics-for-Data-Analysis):
      
      + [Data-Visualization-and-Dashboards-with-Excel-and-Cognos](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/02%20-%20Data-Visualization-and-Dashboards-with-Excel-and-Cognos): This section introduces essential concepts and techniques for data visualization and dashboard creation using Excel and IBM Cognos. It includes a series of projects that cover topics such as creating interactive charts, generating detailed reports, and building dynamic dashboards for data analysis. The projects focus on visualizing sales data, analyzing customer sentiment, and tracking performance metrics, providing a comprehensive understanding of data-driven decision-making. Here’s what’s covered:
         
         + [Project_01_Car Sales](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/02%20-%20Data-Visualization-and-Dashboards-with-Excel-and-Cognos/Project_01_Car%20Sales.xlsx): This Excel file contains data related to car sales performance, focusing on various metrics such as profit, quantity sold, and dealership performance. The data provides insights into the trends in car sales, allowing for analysis of profitability across different dealers.
       
         + [Project_02_Car Sales](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/02%20-%20Data-Visualization-and-Dashboards-with-Excel-and-Cognos/Project_02_Car%20Sales.xlsx): This file includes detailed sales data, breaking down sales by car model, region, and time period. The dataset allows for comparison between different car models and regions, providing a basis for analyzing sales trends and identifying the top-performing models and regions.
       
         + [Project_03_Car Sales](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/02%20-%20Data-Visualization-and-Dashboards-with-Excel-and-Cognos/Project_03_Car%20Sales.xlsx): This dataset presents car sales by dealership, model, and sales month. The data is structured to support the analysis of how sales fluctuate over time and across different regions and dealers, with an emphasis on tracking seasonal sales trends.
       
         + [Project_4_CarSalesByModelEnd](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/02%20-%20Data-Visualization-and-Dashboards-with-Excel-and-Cognos/Project_4_CarSalesByModelEnd.xlsx): This file offers a detailed breakdown of car sales by specific models and sales periods. It provides insights into the end-of-year sales performance for various car models, highlighting which models performed best in specific timeframes.
       
         + [Project_5_Cagnos](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/02%20-%20Data-Visualization-and-Dashboards-with-Excel-and-Cognos/Project_5_Cagnos.pdf): This document provides a detailed analysis of car sales data, highlighting key metrics such as profit by dealer, quantity sold by car model, and monthly sales trends. The analysis also includes customer sentiment and recalls per car model, examining the affected systems and how they impact sales and service performance. Visualizations such as bar charts and scatter plots are used to illustrate these insights, offering a clear understanding of sales distribution, profitability, and recall frequency.    
    
         + [README](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/02%20-%20Data-Visualization-and-Dashboards-with-Excel-and-Cognos/README.md): This README outlines the structure and key insights from the car sales analysis project, providing detailed descriptions of the datasets, visualizations, and metrics used. The analysis covers car sales performance, profit trends, customer sentiment, and recall impacts, offering a comprehensive understanding of the data through various Excel files and a visual report.
      
      + [Python-for-Data-Science-AI-and-Development](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development): This section introduces the essential operations and concepts in Python programming for data science, AI, and development. It includes a series of notebooks covering topics such as basic Python syntax, data structures (lists, dictionaries, sets), object-oriented programming, file handling, working with NumPy and Pandas, and accessing web data through APIs and web scraping. Here’s what’s covered:
        
         + [Project_01_Types, Expressions, and Variables](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_01_Types%2C%20Expressions%2C%20and%20Variables.ipynb): This notebook covers the basics of Python data types, variable assignments, and expressions. It introduces key concepts like integers, floats, and basic arithmetic operations.
           
         + [Project_02_Strings](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_02_Strings.ipynb): This notebook dives into string manipulation in Python. It covers operations like slicing, concatenation, and string formatting.
           
         + [Project_03_Lists](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_03_Lists.ipynb): This notebook focuses on Python lists, covering essential list operations such as indexing, slicing, appending, and removing elements.

           
         + [Project_04_Tuples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_04_Tuples.ipynb): This notebook introduces Python tuples, explaining their immutable nature and their basic operations like indexing and slicing. 
           
         + [Project_05_Dictionaries](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_05_Dictionaries.ipynb): This notebook explains Python dictionaries, covering key-value pairs, accessing, adding, updating, and deleting items in dictionaries, and looping through dictionary elements.
           
         + [Project_06_Sets](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_06_Sets.ipynb): This notebook explores Python sets, discussing their unique element property, and set operations like unions, intersections, and differences.
           
         + [Project_07_Conditions and Branching](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_07_Conditions%20and%20Branching.ipynb): This notebook covers conditional statements (if, else, elif) and logical operators to create decision-making code.
           
         + [Project_08_Loops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_08_Loops.ipynb): This notebook introduces loops in Python (for and while loops), along with break and continue statements to control the flow of iteration.
           
         + [Project_09_Functions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_09_Functions.ipynb): This notebook dives into creating and using functions in Python, including passing arguments, returning values, and using default parameters.
           
         + [Project_10_Exception Handling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_10_Exception%20Handling.ipynb): This notebook explains how to handle errors using try, except, and finally blocks to catch and manage exceptions in Python programs.
           
         + [Project_11_Objects and Classes](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_11_Objects%20and%20Classes.ipynb): This notebook introduces Object-Oriented Programming (OOP) concepts in Python, covering how to create and use classes and objects, encapsulation, and method definitions.
           
         + [Project_12_Reading Files with Open](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_12_Reading%20Files%20with%20Open.ipynb): This notebook focuses on reading text files using Python's open() function. It demonstrates various file modes and methods for reading file content, such as read(), readline(), and readlines().
           
         + [Project_13_Writing Files with Open](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_13_Writing%20Files%20with%20Open.ipynb): This notebook teaches how to write data to files using Python's open() function. It covers writing in different modes (write, append) and handling file paths.
           
         + [Project_14_Loading Data with Pandas](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_14_Loading%20Data%20with%20Pandas.ipynb): This notebook introduces the Pandas library for loading and manipulating data. It covers reading data from CSV files, creating DataFrames, and performing basic data operations.
           
         + [Project_15_One Dimensional Numpy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_15_One%20Dimensional%20Numpy.ipynb): This notebook explores one-dimensional arrays in NumPy, including creating, indexing, slicing, and performing basic operations on arrays.
           
         + [Project_16_Two Dimensional Numpy](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_16_Two%20Dimensional%20Numpy.ipynb): This notebook expands on NumPy by introducing two-dimensional arrays (matrices), covering indexing, slicing, and performing matrix operations.
           
         + [Project_17_Introduction to API](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_17_Introduction%20to%20API.ipynb): This notebook introduces APIs, explaining how to interact with web services and retrieve data using HTTP requests, primarily using the Python requests library.
           
         + [Project_18_Access REST APIs & Request HTTP](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_18_Access%20REST%20APIs%20%26%20Request%20HTTP.ipynb): This notebook provides practical examples of working with REST APIs, including sending GET and POST requests and handling JSON responses.
           
         + [Project_19_API Examples](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_19_API%20Examples.ipynb): This notebook provides examples of accessing different APIs, extracting data, and converting the data into a Pandas DataFrame for analysis.
         
         + [Project_20_Webscraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/03%20-%20Python-for-Data-Science-AI-and-Development/Project_20_Webscraping.ipynb): This notebook covers web scraping techniques using Python’s BeautifulSoup and requests libraries. It demonstrates how to extract data from HTML pages and scrape tabular data using Pandas.
    
      + [Python-Project-for-Data-Science](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/04%20-%20Python-Project-for-Data-Science): This section introduces the practical application of Python programming for data science through a hands-on project. It includes a single notebook that focuses on extracting and visualizing stock data, using tools such as yfinance for financial data extraction, BeautifulSoup for web scraping revenue data, and Plotly for data visualization. Here’s what’s covered:
        
         + [Project_Final Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/04%20-%20Python-Project-for-Data-Science/Project_Final%20Assignment.ipynb): Focuses on extracting and visualizing stock market data using Python. The project involves retrieving Tesla and GameStop stock data using the yfinance library and extracting revenue data through web scraping with BeautifulSoup. A custom function was defined to plot stock data, and Plotly was used to create visualizations of the stock and revenue data for both companies. This assignment demonstrates skills in data extraction, web scraping, and visualization, showcasing practical applications of these techniques in financial data analysis.
      
      + [Databases-and-SQL-for-Data-Science-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/05%20-%20Databases-and-SQL-for-Data-Science-with-Python): This section introduces the essential operations and concepts in SQL for working with databases and performing data analysis. It includes a series of notebooks covering topics such as inserting and updating data in SQLite, using SQL Magic commands in Jupyter, advanced data analysis with SQL queries, and hands-on practice with real-world datasets. Here’s what’s covered:
        
         + [Project_1_Insert_Update_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/05%20-%20Databases-and-SQL-for-Data-Science-with-Python/Project_1_Insert_Update_SQLite.ipynb): This notebook covers basic SQL operations such as inserting and updating records in a SQLite database. Learners are guided through the process of writing queries to add new data to tables and modify existing data. 
           
         + [Project_2_SQLmagic_SQlite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/05%20-%20Databases-and-SQL-for-Data-Science-with-Python/Project_2_SQLmagic_SQlite.ipynb): This notebook introduces the use of SQL Magic commands in Jupyter Notebook to interact with SQLite databases. It demonstrates how to run SQL queries directly within the notebook environment using magic commands, providing a convenient way to explore and analyze data.
           
         + [Project_3_Analyzing_SQLite](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/05%20-%20Databases-and-SQL-for-Data-Science-with-Python/Project_3_Analyzing_SQLite.ipynb): This notebook focuses on more advanced SQL queries for data analysis. It includes exercises on using aggregate functions, filtering data, and joining tables to extract meaningful insights from datasets.
           
         + [Project_4_RealDataPractice-v5_sqlite_Learner](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/05%20-%20Databases-and-SQL-for-Data-Science-with-Python/Project_4_RealDataPractice-v5_sqlite_Learner.ipynb): This notebook provides hands-on practice with a real-world dataset using SQLite. Learners are tasked with writing complex SQL queries, using subqueries, and performing data analysis to answer specific business questions. It also covers visualization techniques using Python alongside SQL to better understand the data.
      
      + [Data-Analysis-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python): This section provides a comprehensive introduction to data analysis using Python. It includes a series of notebooks covering essential topics such as data wrangling, visualization, regression models, and machine learning techniques. The projects focus on manipulating datasets using libraries like Pandas and NumPy, performing exploratory data analysis, and building predictive models. Here’s what’s covered:

         + [Project_01_Introduction](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_01_Introduction.ipynb): This notebook introduces basic data acquisition techniques, demonstrating how to load datasets into Python using Pandas. The example dataset used is related to automobiles, and the notebook covers how to gain basic insights through descriptive statistics.
       
         + [Project_02_Practice data loading](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_02_Practice%20data%20loading.ipynb): Focuses on practicing data loading techniques using a laptop pricing dataset. The notebook demonstrates importing CSV files into Pandas and explores basic data cleaning, such as handling missing values and checking data types.
       
         + [Project_03_Review Data Wrangling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_03_Review%20Data%20Wrangling.ipynb): Covers essential data wrangling techniques, including identifying and handling missing values, converting data types, and generating indicator variables. The notebook prepares the dataset for further analysis through cleaning and transformation.
       
         + [Project_04_Practice datawrangling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_04_Practice%20datawrangling.ipynb): Provides hands-on practice in cleaning and transforming data, covering tasks such as handling missing values, standardizing and normalizing features, and converting categorical variables into numerical indicators, with visualizations of binned data.
       
         + [Project_05_Exploratory data analysis cars](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_05_Exploratory%20data%20analysis%20cars.ipynb): This notebook performs exploratory data analysis on a car dataset. It explores correlations between various numerical and categorical features and price, using regression plots and boxplots to identify key variables for future modeling.
       
         + [Project_06_Parctice Exploratory data analysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_06_Parctice%20Exploratory%20data%20analysis.ipynb): Focuses on analyzing the relationship between laptop features and prices. The notebook covers visualizing feature distributions, performing descriptive statistical analysis, and calculating Pearson correlation to identify important predictors.
       
         + [Project_07_Review Model Development](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_07_Review%20Model%20Development.ipynb): This notebook explores different regression models, including simple and multiple linear regression, as well as polynomial regression. It compares models using metrics such as MSE and R², concluding that multiple linear regression provides the best fit for predicting car prices.
       
         + [Project_08_Practice Model Development Laptops](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_08_Practice%20Model%20Development%20Laptops.ipynb): Demonstrates building predictive models for laptop prices using simple, multiple, and polynomial regression. A pipeline is used for scaling, transforming, and fitting the model, with model performance evaluated based on R² and MSE.
       
         + [Project_09_Model Evaluation and Refinement cars](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_09_Model%20Evaluation%20and%20Refinement%20cars.ipynb): This notebook focuses on evaluating regression models using cross-validation and refining them with Ridge regression to prevent overfitting. The best model is selected by tuning hyperparameters and assessing performance with R² and MSE.
       
         + [Project_10_Practice Model Evaluation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_10_Practice%20Model%20Evaluation.ipynb): Evaluates and refines laptop price prediction models through cross-validation, Ridge regression, and hyperparameter tuning using Grid Search. The notebook focuses on improving model performance by selecting optimal hyperparameters and testing on unseen data.
       
         + [Project_11_House Sales in King Count USA](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/06%20-%20Data-Analysis-with-Python/Project_11_House%20Sales%20in%20King%20Count%20USA.ipynb): In this project, the objective is to predict house prices in King County, USA, using various features such as square footage, number of bedrooms, and floors. The notebook covers essential steps including data wrangling, exploratory data analysis, and the development of regression models to estimate housing prices. The final phase involves evaluating and refining the models to enhance predictive accuracy, making this project a comprehensive exploration of real estate data analytics.
        
      + [Data-Visualization-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python): This section introduces essential concepts and techniques for data visualization using Python. It includes a series of notebooks covering topics such as creating visualizations with Matplotlib, generating advanced plots like waffle charts and word clouds, and mapping geospatial data with Folium. These projects focus on effectively visualizing data to uncover insights. Here’s what’s covered:
    
         + [Project_1_Dataset Preprocessing Exploring with Pandas](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_1_Dataset%20Preprocessing%20Exploring%20with%20Pandas.ipynb): This notebook serves as a refresher on using the Pandas library for data exploration and preprocessing. It covers essential techniques for wrangling data, including sorting, filtering, and selecting data based on conditions. The example dataset used focuses on immigration to Canada from 1980 to 2013. This project provides a foundation for preparing datasets before applying data visualization techniques.
    
         + [Project_2_Introduction to Matplotlib and Line Plots](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_2_Introduction%20to%20Matplotlib%20and%20Line%20Plots.ipynb): This notebook introduces the basics of data visualization using the Matplotlib library. It focuses on creating line plots to visualize trends in data, specifically using the example of immigration to Canada from 1980 to 2013. The notebook covers essential plotting techniques and provides insights on customizing plots, making it a useful starting point for anyone learning how to visualize data with Matplotlib.
    
         + [Project_3_Pie Charts Box Plots Scatter Plots and Bubble Plots](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_3_Pie%20Charts%20Box%20Plots%20Scatter%20Plots%20and%20Bubble%20Plots.ipynb): This notebook introduces various data visualization techniques using Matplotlib, including pie charts, box plots, scatter plots, and bubble plots. These visualizations are useful for displaying data distributions, identifying outliers, and comparing multiple variables. The notebook explores different plotting methods, with a focus on interpreting data effectively through visual representations. It uses an example dataset on immigration to Canada from 1980 to 2013.
    
         + [Project_4_Plotting directly with Matplotlib](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_4_Plotting%20directly%20with%20Matplotlib.ipynb): This notebook provides a hands-on introduction to plotting directly using Matplotlib. It covers key concepts such as customizing plots with markers, colors, and line styles, as well as creating subplots to display multiple visualizations simultaneously. The example dataset focuses on visualizing immigration data to Canada from 1980 to 2013. Additionally, the notebook demonstrates how to fine-tune plot aesthetics, including grid lines, legends, axis limits, and titles.
    
         + [Project_5_Waffle Charts Word Clouds and Regression Plots](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_5_Waffle%20Charts%20Word%20Clouds%20and%20Regression%20Plots.ipynb): This notebook explores advanced visualization techniques, including waffle charts, word clouds, and regression plots. Using the Matplotlib and PyWaffle libraries, the notebook demonstrates how to create waffle charts to show proportions of categories, generate word clouds for text-based data visualization, and use Seaborn to produce regression plots that highlight trends and relationships between variables. The example dataset focuses on immigration to Canada from 1980 to 2013.
    
         + [Project_6_Creating maps visualizing geospat](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_6_Creating%20maps%20visualizing%20geospat.ipynb): This notebook focuses on geospatial data visualization using the Folium library. It introduces how to create various types of maps, including choropleth maps, to visualize data on a geographical scale. Using immigration data to Canada from 1980 to 2013, the notebook demonstrates how to generate maps that represent the total number of immigrants from different countries. This project showcases how to effectively combine data analysis and mapping techniques to reveal spatial trends.
    
         + [Project_7_Practice_Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_7_Practice_Assignment.ipynb): This notebook focuses on visualizing and analyzing wildfire activities in Australia. It uses libraries like Pandas, Seaborn, and Folium to create informative plots and charts. The project guides users through tasks involving geospatial data mapping, where markers represent different regions of Australia. It also demonstrates how to plot the geographical locations of wildfires on a map using Folium, providing a practical application of data visualization for disaster analysis.
    
         + [Project_8_Final Assignment](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/07%20-%20Data-Visualization-with-Python/Project_8_Final%20Assignment.ipynb): This notebook guides users through a comprehensive analysis of automobile sales during recession periods. It demonstrates how to create visualizations using libraries such as Seaborn and Folium. The analysis covers vehicle-wise sales during recession and non-recession periods and includes tasks such as generating bar charts and choropleth maps to show the geographical impact of recessions on automobile sales. This final project provides a hands-on approach to combining data analysis and visualization techniques to gain insights from real-world data.
      
      + [Data-Analyst-Capstone-Project](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project): This section provides a comprehensive application of data analysis techniques. It includes a series of projects focused on data collection, data wrangling, exploratory data analysis, and data visualization. The projects cover real-world scenarios such as job market analysis, web scraping, and API data retrieval, offering insights into how data-driven decision-making can be applied across various domains. Here’s what’s covered:
         
         + [Project_00_Jobs_API](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_00_Jobs_API.ipynb): This notebook explores how to collect job data using an API. It demonstrates how to make HTTP requests to job search platforms, retrieve job postings, and process the returned data. The project focuses on building a dataset from job listings, preparing it for further analysis, and understanding trends in the job market.
       
         + [Project_01_Requests_HTTP](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_01_Requests_HTTP.ipynb): This notebook covers the basics of making HTTP requests using Python's requests library. It explains how to send GET and POST requests to APIs, handle responses, and extract data from the returned JSON objects. This project provides foundational knowledge for working with APIs in data collection projects.
       
         + [Project_02_Collecting_Jobs_data_Using_API-Questions](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_02_Collecting_Jobs_data_Using_API-Questions.ipynb): This project builds on API usage to collect job data, with a focus on answering specific business questions. It demonstrates how to query APIs for targeted information such as job titles, locations, and salary data, helping to answer key queries for job market analysis.
       
         + [Project_03_Web-Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_03_Web-Scraping.ipynb): This notebook focuses on web scraping techniques using BeautifulSoup and Python. The project demonstrates how to extract job data from websites, convert it into structured datasets, and prepare it for analysis. It covers the essentials of parsing HTML, navigating through tags, and cleaning the extracted data.
       
         + [Project_04_Web-Scraping](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_04_Web-Scraping.ipynb): This is a continuation of the web scraping project, where more advanced scraping techniques are applied to job listing sites. The project expands on collecting large datasets, dealing with pagination, and handling dynamic web content.
       
         + [Project_05_ExploreDataSet](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_05_ExploreDataSet.ipynb): This project is dedicated to exploring the job dataset collected from APIs and web scraping. It uses techniques like data visualization, descriptive statistics, and data filtering to provide insights into job market trends, job postings distribution, and salary patterns.
       
         + [Project_06_DataWrangling](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_06_DataWrangling.ipynb): This notebook covers data wrangling techniques applied to the job dataset. It includes cleaning missing values, transforming variables, and standardizing the dataset to prepare it for analysis and machine learning applications. The project ensures data quality for further stages of analysis.
       
         + [Project_07_ExploratoryDataAnalysis](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_07_ExploratoryDataAnalysis.ipynb): This project focuses on performing exploratory data analysis (EDA) on the job dataset. The notebook walks through generating visualizations, calculating summary statistics, and identifying key trends in job postings, such as the distribution of salaries and job locations.
       
         + [Project_08_DataVisualization-lab](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_08_DataVisualization-lab.ipynb): This notebook is dedicated to creating data visualizations from the job dataset. It covers the use of libraries like Matplotlib and Seaborn to build charts and graphs that display trends in job postings, salary distributions, and geographic job availability.
       
         + [Project_Cagnos](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Project_Cagnos.pdf): This document provides a comprehensive analysis of car sales data, focusing on key metrics such as profit by dealer, quantity sold by model, and monthly sales performance. It includes detailed visualizations, showing trends in sales, customer sentiment, and system recalls per car model. The analysis offers insights into the relationship between sales and profitability, along with the impact of recalls on service performance.
       
         + [Technology Trends And Analysis Presentation](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/Technology%20Trends%20And%20Analysis%20Presentation.pdf): This presentation provides an in-depth analysis of current technology trends and their impact across various industries. It explores key technological advancements, emerging trends, and their potential applications. The presentation focuses on how businesses and individuals can leverage these innovations for growth and competitive advantage in an increasingly digital world.
       
         + [README](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/04%20-%20IBM-Data-Analyst-Professional-Certificate/08%20-%20Data-Analyst-Capstone-Project/README.md): This README outlines the structure and key components of the Data Analyst Capstone Project, detailing the steps taken in data collection, wrangling, analysis, and visualization. The project applies data-driven techniques to real-world scenarios, providing insights into job market trends, web scraping, and API data analysis.
      
   + [Google-Advanced-Data-Analytics-Professional-Certificate](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate): Advanced data analytics and machine learning techniques:

      + [Get-Started-with-Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python): This section provides an introduction to core concepts in Python programming and data manipulation, laying a strong foundation for data analysis. The notebooks cover a progression of topics, starting with basic Python syntax and advancing to data structures, string manipulation, loops, and conditional statements. Further projects dive into using libraries like NumPy for array and vector operations, pandas for dataframes, and exploratory data analysis (EDA) on real-world datasets. Here’s what’s covered:
    
         + [Project_01_Hello, Python!](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_01_Hello%2C%20Python!.ipynb): This project introduces the basics of Python through an annotated guide. It covers fundamental concepts like variable types, object-oriented programming, and data conversions, along with example code to help beginners get comfortable with the language.
           
         + [Project_02_Use Python syntax_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_02_Use%20Python%20syntax_Part1.ipynb): This notebook covers Python syntax essentials by creating and manipulating variables. Exercises simulate an analysis of cinema users, exploring data types, conversions, and precise variable naming.
       
         + [Project_03_Use Python syntax_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_03_Use%20Python%20syntax_Part2.ipynb): This project reinforces foundational concepts by comparing work with a completed example, focusing on Python syntax through a cinema-based scenario.
       
         + [Project_04_Functions and conditional statements](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_04_Functions%20and%20conditional%20statements.ipynb): This project focuses on Python functions and conditional structures. It includes defining functions, maintaining clean code, and using if/elif/else statements for decision-making.
       
         + [Project_05_ Functions_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_05_%20Functions_Part1.ipynb): This project emphasizes the importance of functions for automating repetitive tasks. It involves defining a function to calculate cinema revenue based on the number of tickets sold, reinforcing function fundamentals and coding best practices.
       
         + [Project_06_ Functions_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_06_%20Functions_Part2.ipynb): A continuation of work on functions that provides a complete example for comparison. This project solidifies skills in defining and using functions effectively.
       
         + [Project_07_Conditional statements_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_07_Conditional%20statements_Part1.ipynb): This project teaches the use of operators and conditional structures to perform operations on variables. It includes marketing tasks, such as determining when to send a marketing email based on user behavior.
       
         + [Project_08_Conditional statements_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_08_Conditional%20statements_Part2.ipynb): The second part of the conditional statements project, providing a complete example to review and strengthen understanding of Python conditional structures.
       
         + [Project_09_Loops and strings](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_09_Loops%20and%20strings.ipynb): This project explores loops and string manipulation in Python, including for and while loops, string slicing, and formatting. It demonstrates how to automate repetitive processes and handle text data efficiently.
       
         + [Project_10_ While loops_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_10_%20While%20loops_Part1.ipynb): This project introduces while loops for automating repeated processes, with an exercise on managing coupon alerts for customer purchases. It is useful for automating tasks that require repeated comparisons.
       
         + [Project_11_While loops_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_11_While%20loops_Part2.ipynb): This notebook provides an example on using while loops to automate repetitive tasks, with a focus on marketing tasks such as managing coupon alerts for customer purchases. It covers repeated comparisons and efficient process automation.
       
         + [Project_12_ For loops_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_12_%20For%20loops_Part1.ipynb): This project introduces for loops to automate tasks, such as comparing averages across survey categories. The exercises illustrate how to make repetitive tasks more efficient using iterative statements.
       
         + [Project_13_ For loops_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_13_%20For%20loops_Part2.ipynb): This project continues with for loops, comparing exercises with a completed example for clarity. It reinforces how to use for loops effectively in scenarios involving repetitive analysis tasks.
       
         + [Project_14_Strings_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_14_Strings_Part1.ipynb): This notebook focuses on string manipulation. It introduces tasks involving store IDs, ZIP codes, and custom URLs, helping to build familiarity with handling textual data as part of data analysis.
       
         + [Project_15_Strings_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_15_Strings_Part2.ipynb): This part extends string manipulation skills, with example exercises to review item descriptions or customer names. It further demonstrates how to manage and process strings in various data scenarios.
       
         + [Project_16_Data structures in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_16_Data%20structures%20in%20Python.ipynb): This project covers Python’s essential data structures, including lists, tuples, dictionaries, and sets. Exercises focus on modifying and organizing data to answer specific questions, using real-world air quality data from the U.S. EPA as a context.
       
         + [Project_17_ Lists & tuples_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_17_%20Lists%20%26%20tuples_Part1.ipynb): This notebook introduces lists and tuples, focusing on creating and modifying these data structures. It uses air quality data to illustrate the organization and easy access of data in research tasks.
       
         + [Project_18_ Lists & tuples_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_18_%20Lists%20%26%20tuples_Part2.ipynb): Continuing with lists and tuples, this project provides a full example of tasks, further demonstrating data organization and manipulation techniques essential for research and analysis.
       
         + [Project_19_ Dictionaries & sets_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_19_%20Dictionaries%20%26%20sets_Part1.ipynb): This project explores dictionaries and sets, using air quality index (AQI) data from the U.S. EPA. It introduces methods for creating and updating dictionaries and sets, showcasing how to store and retrieve information effectively.
       
         + [Project_20_ Dictionaries & sets_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_20_%20Dictionaries%20%26%20sets_Part2.ipynb): The second part of dictionaries and sets, this notebook offers an in-depth example with AQI data. It covers advanced techniques for managing data in dictionaries and sets, essential for data organization and access in larger datasets.
       
         + [Project_21_ Arrays and vectors with NumPy_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_21_%20Arrays%20and%20vectors%20with%20NumPy_Part1.ipynb): This notebook introduces working with NumPy arrays, focusing on handling air quality index (AQI) data. It covers fundamental operations with arrays, allowing for calculations and evaluations within numerical data contexts, such as air pollution analysis.
       
         + [roject_22_ Arrays and vectors with NumPy_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_22_%20Arrays%20and%20vectors%20with%20NumPy_Part2.ipynb): This continuation of NumPy arrays delves deeper into vector operations. The exercises focus on using arrays to conduct further AQI data analysis, reinforcing skills in efficient data manipulation and evaluation.
       
         + [Project_23_ Dataframes with pandas_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_23_%20Dataframes%20with%20pandas_Part1.ipynb): This project introduces pandas dataframes, using air quality data to practice loading, examining, and manipulating dataframes. Topics include summary statistics, iloc indexing, sorting, Boolean masking, grouping, and concatenation to prepare for more detailed analysis.
       
         + [Project_24_ Arrays and vectors with NumPy_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_24_%20Arrays%20and%20vectors%20with%20NumPy_Part2.ipynb): This notebook contains similar content to Project 22, focusing on AQI data analysis with NumPy arrays and reinforcing array manipulation and evaluation.
       
         + [Project_25_Automatidata project_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_25_Automatidata%20project_Part1.ipynb): In this project, a fictional consulting firm, Automatidata, assists the New York City Taxi and Limousine Commission with data preparation for analysis. Tasks involve initial data inspection, understanding key variables, and creating a pandas dataframe to prepare for future exploration, visualizations, and hypothesis testing.
       
         + [Project_26_ Course 2 Python Notebook_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_26_%20Course%202%20Python%20Notebook_Part2.ipynb): Part of the Automatidata project, this notebook involves a closer inspection and understanding of the New York City TLC data. It emphasizes data readiness for exploratory data analysis (EDA) by focusing on variable inspection and compiling a summary of key insights.
       
         + [Project_27_TikTok project_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_27_TikTok%20project_Part1.ipynb): This project simulates data preparation for a classification model at TikTok. It involves data inspection and EDA preparation to explore potential insights within the dataset, setting up the data for further statistical analysis and model development.
       
         + [Project_28_TikTok project_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_28_TikTok%20project_Part2.ipynb): A continuation of the TikTok project, this part delves into data organization, dataframe creation, and the inspection of specific variables. It emphasizes preparing the data for in-depth EDA, hypothesis testing, and model preparation.
       
         + [Project_29_Waze project_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_29_Waze%20project_Part1.ipynb): This project simulates data preparation for a user churn analysis at Waze. It involves data inspection and preliminary analysis to ensure the dataset is structured for visualization and statistical analysis, focusing on user behavior insights.
       
         + [Project_30_Waze project_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/01%20-%20Get-Started-with-Python/Project_30_Waze%20project_Part2.ipynb): A continuation of the Waze project, this notebook focuses on variable inspection and compiling insights for user churn analysis. It emphasizes setting up the dataset for hypothesis testing and exploratory data analysis.
      
      + [Go-Beyond-the-Numbers-Translate-Data-into-Insights](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights): This section introduces essential techniques for translating data into meaningful insights, emphasizing exploratory data analysis (EDA), data cleaning, and visualization. The series of notebooks covers practical applications in data preparation and storytelling through Python and Tableau, with projects that involve handling real-world datasets from domains such as social media, transportation, and finance. Here’s what’s covered:

         + [Project_01_EDA using basic data functions with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_01_EDA%20using%20basic%20data%20functions%20with%20Python.ipynb): This project introduces essential exploratory data analysis (EDA) techniques using foundational data functions in Python. It emphasizes understanding dataset characteristics and preparing for detailed data analysis.
       
         + [Project_02_Discover what is in your dataset_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_02_Discover%20what%20is%20in%20your%20dataset_Part1.ipynb): This notebook focuses on EDA by exploring a dataset on unicorn companies, valued at over $1 billion. Key tasks involve identifying patterns in industries, countries, and funding sources to inform investment recommendations.
       
         + [Project_03_Discover what is in your dataset_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_03_Discover%20what%20is%20in%20your%20dataset_Part2.ipynb): The second part of the unicorn companies EDA project, this notebook includes visualization techniques to further uncover insights and enhance understanding of the dataset's structure.
       
         + [Project_04_Date string manipulations with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_04_Date%20string%20manipulations%20with%20Python.ipynb): This project covers essential date and string manipulation techniques, helping in parsing, transforming, and organizing date-based data for more refined analysis.
       
         + [Project_05_EDA structuring with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_05_EDA%20structuring%20with%20Python.ipynb): This project provides guidelines for structuring data for EDA. It emphasizes organizing data effectively to allow meaningful insights, using methods to explore and prepare datasets efficiently.
       
         + [Project_06_Structure your data_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_06_Structure%20your%20data_Part1.ipynb): This notebook guides data structuring with datetime transformations, focusing on organizing unicorn company data to discover meaningful trends in the timing of company growth.
       
         + [Project_07_Structure your data_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_07_Structure%20your%20data_Part2.ipynb): Continuing with data structuring, this part deepens insights into organizing data through transformations, enabling efficient exploration of dataset characteristics and trend identification.
       
         + [Project_08_Dealing with missing data in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_08_Dealing%20with%20missing%20data%20in%20Python.ipynb): This project addresses common issues with missing data, exploring methods to clean datasets effectively. It includes practical approaches to handling incomplete data in preparation for robust analysis.
       
         + [Project_09_Address missing data_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_09_Address%20missing%20data_Part1.ipynb): This notebook applies techniques for identifying and addressing missing data in a financial dataset on unicorn companies, allowing for a more reliable basis for further EDA and trend analysis.
       
         + [Project_10_Address missing data_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_10_Address%20missing%20data_Part2.ipynb): The final part of the missing data project, this notebook emphasizes advanced techniques for handling missing data, focusing on producing clean, complete datasets for insightful visualizations and analyses.
       
         + [Project_11_Validate and clean your data_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_11_Validate%20and%20clean%20your%20data_Part1.ipynb): This project covers fundamental data preparation techniques, including input validation and label encoding, essential for ensuring clean and analyzable datasets. It uses a dataset on unicorn companies to explore best practices in data validation for reliable insights.
       
         + [Project_12_Validate and clean your data_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_12_Validate%20and%20clean%20your%20data_Part2.ipynb): This continuation of data validation and cleaning focuses on refining the unicorn dataset further, ensuring data accuracy and completeness for robust exploratory data analysis.
       
         + [Project_13_Automatidata project_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_13_Automatidata%20project_Part1.ipynb): This project simulates a data analysis task for the New York City Taxi and Limousine Commission. It involves structuring and cleaning taxi ride data, using Python to prepare visualizations and explore ride durations, seasonal patterns, and more, setting the stage for further insights.
       
         + [Project_14_Automatidata project_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_14_Automatidata%20project_Part2.ipynb): Building on previous work, this project extends EDA on the New York City taxi dataset. It includes creating visualizations with tools like Matplotlib and Seaborn and designing a Tableau dashboard to present insights on monthly taxi ridership across the city.
       
         + [Project_15_TikTok project_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_15_TikTok%20project_Part1.ipynb): This project involves data preparation for a TikTok dataset, focusing on differentiating claim videos from opinion videos. It includes initial EDA steps, such as data structuring, cleaning, and basic visualizations to understand user engagement metrics.
       
         + [Project_16_TikTok project_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_16_TikTok%20project_Part2.ipynb): Expanding on the TikTok dataset, this project delves deeper into data visualization and analysis. It provides insights through visual comparisons of claims versus opinions, exploring key metrics like view counts, likes, and author statuses.
       
         + [Project_17_Waze project_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_17_Waze%20project_Part1.ipynb): This project simulates EDA for Waze's user data, focusing on understanding user behavior to inform churn analysis. It emphasizes data structuring, cleaning, and visualizing user patterns to support further analysis.
       
         + [Project_18_Waze project_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/02%20-%20Go-Beyond-the-Numbers-Translate-Data-into-Insights/Project_18_Waze%20project_Part2.ipynb): Continuing the Waze project, this notebook expands on visualizations and provides insights into user activity. It includes summary statistics and visual storytelling techniques, preparing data for more detailed churn analysis.
      
      + [The-Power-of-Statistics](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics): This section delves into the essential statistical methods used to analyze and interpret data effectively. It includes a series of notebooks covering topics such as descriptive statistics, probability distributions, sampling, confidence intervals, and hypothesis testing. Here’s what’s covered:
    
         + [Project_01_Compute descriptive statistics with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_01_Compute%20descriptive%20statistics%20with%20Python.ipynb): This project introduces descriptive statistics to summarize data, focusing on understanding data distribution and spread. Key concepts include calculating measures of central tendency and variability, providing insights into dataset characteristics.
       
         + [Project_02_Explore descriptive statistics_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_02_Explore%20descriptive%20statistics_Part1.ipynb): This notebook explores descriptive statistics using air quality data from the EPA. The focus is on understanding carbon monoxide pollution across multiple sites, using statistical summaries to convey data distribution and trends.
       
         + [Project_03_Explore descriptive statistics_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_03_Explore%20descriptive%20statistics_Part2.ipynb): Continuing the analysis on air quality data, this part emphasizes deeper statistical exploration, reinforcing concepts of spread and central tendency to reveal detailed insights.
       
         + [Project_04_Work with probability distributions in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_04_Work%20with%20probability%20distributions%20in%20Python.ipynb): This project focuses on probability distributions, using the normal distribution and z-scores to detect outliers. It provides methods to assess data distribution, with applications to air quality data.
       
         + [Project_05_Explore probability distributions_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_05_Explore%20probability%20distributions_Part1.ipynb): This notebook applies probability distributions to air quality data, focusing on identifying regions needing environmental intervention. It covers z-scores and outlier detection for effective data analysis.
       
         + [Project_06_Explore probability distributions_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_06_Explore%20probability%20distributions_Part2.ipynb): A continuation of probability analysis, this part reinforces methods for understanding and applying distributions in environmental data contexts, with a focus on air quality insights.
       
         + [Project_07_ Sampling with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_07_%20Sampling%20with%20Python.ipynb): This project introduces sampling techniques to create representative subsets of large datasets. Using air quality data, it demonstrates how sampling improves efficiency in analysis and inference.
       
         + [Project_08_Explore sampling_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_08_Explore%20sampling_Part1.ipynb): This notebook explores effective sampling methods to handle extensive datasets. It applies sampling on EPA data to estimate population parameters and analyze air quality trends efficiently.
       
         + [Project_09_Explore sampling_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_09_Explore%20sampling_Part2.ipynb): A continuation of sampling techniques, this part deepens sampling practices, providing strategies for making reliable estimates from large datasets, using EPA air quality data.
       
         + [Project_10_Confidence intervals in Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_10_Confidence%20intervals%20in%20Python.ipynb): This project covers constructing confidence intervals for point estimates, providing insights into the reliability of sample statistics. It applies confidence intervals to infer trends in air quality data.
       
         + [Project_11_Confidence intervals in Python_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_11_Confidence%20intervals%20in%20Python_Part1.ipynb): This project introduces confidence intervals, focusing on the Air Quality Index (AQI) data to assess public health risk across various states. It explores methods for constructing confidence intervals to estimate which states might be affected by potential federal policy changes.
       
         + [Project_12_Confidence intervals in Python_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_12_Confidence%20intervals%20in%20Python_Part2.ipynb): A continuation of confidence interval analysis, this notebook further refines interval estimates to assess state-specific AQI data, providing insights for renewable energy policy discussions.
       
         + [Project_13_Use Python to conduct a hypothesis test](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_13_Use%20Python%20to%20conduct%20a%20hypothesis%20test.ipynb): This project guides hypothesis testing using a two-sample test, applying statistical methods to examine differences in sample means, with examples on environmental data.
       
         + [Project_14_Use Python to conduct a hypothesis test_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_14_Use%20Python%20to%20conduct%20a%20hypothesis%20test_Part1.ipynb): This notebook uses AQI data for hypothesis testing, focusing on formulating and conducting hypothesis tests to prioritize air quality improvement strategies.
       
         + [Project_15_Use Python to conduct a hypothesis test_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_15_Use%20Python%20to%20conduct%20a%20hypothesis%20test_Part2.ipynb): A continuation of hypothesis testing with AQI data, this part deepens the understanding of test formulation, interpretation, and its implications for public health policies.
       
         + [Project_16_Automatidata_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_16_Automatidata_Part1.ipynb): Part of the Automatidata series, this project simulates an A/B test for the New York City Taxi & Limousine Commission to analyze fare amounts by payment type, aiming to identify ways to optimize revenue for taxi drivers.
       
         + [Project_17_Automatidata_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_17_Automatidata_Part2.ipynb): A continuation of the NYC TLC A/B test project, this notebook provides detailed hypothesis testing and statistical analysis to determine the impact of payment method on fare amounts.
       
         + [Project_18_TikTok_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_18_TikTok_Part1.ipynb): This project involves hypothesis testing for TikTok, analyzing key metrics to differentiate user engagement between various video types. It includes steps for setting up hypothesis tests to uncover insights into video performance.
       
         + [Project_19_TikTok_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_19_TikTok_Part2.ipynb): A continuation of hypothesis testing on TikTok data, this project applies statistical tests to classify and analyze video engagement, refining data-driven recommendations for content strategy.
       
         + [Project_20_Waze_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_20_Waze_Part1.ipynb): This Waze project applies two-sample hypothesis testing to user ride data, examining differences in mean rides between iPhone and Android users. It offers insights into user behavior based on device type.
       
         + [Project_21_Waze_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/03%20-%20The-Power-of-Statistics/Project_21_Waze_Part2.ipynb): This project is the second part of the Waze user churn analysis, focusing on hypothesis testing to examine ride frequency differences between iPhone and Android users. It employs a two-sample t-test to determine if there is a statistically significant difference in mean rides between the two device types, with recommendations based on the findings.
      
      + [Regression-Analysis-Simplify-Complex-Data-Relationships](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships):

         + [Project_01_Explore linear regression with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_01_Explore%20linear%20regression%20with%20Python.ipynb): This project introduces simple linear regression, guiding through the basics of building a model to analyze relationships between two variables. Key concepts include model creation, fitting, and preliminary data interpretation.
       
         + [Project_02_Run simple linear regression_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_02_Run%20simple%20linear%20regression_Part1.ipynb): This project applies simple linear regression to examine the impact of radio promotions on sales. Using a dataset that includes multiple marketing channels, it provides insights into determining resource allocation based on campaign effectiveness.
       
         + [Project_03_Run simple linear regression_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_03_Run%20simple%20linear%20regression_Part1.ipynb): A continuation of simple linear regression, this notebook offers a step-by-step example to refine understanding of regression analysis on marketing data.
       
         + [Project_04_Evaluate simple linear regression_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_04_Evaluate%20simple%20linear%20regression_Part1.ipynb): This project evaluates a simple linear regression model, assessing its assumptions, analyzing model performance, and interpreting results. It emphasizes understanding relationships between promotional spending and sales revenue.
       
         + [Project_05_Evaluate simple linear regression_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_05_Evaluate%20simple%20linear%20regression_Part2.ipynb): A detailed continuation of regression model evaluation, this part further examines performance metrics and model assumptions, aiding in decision-making for marketing strategies.
       
         + [Project_06_Interpret multiple regression results with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_06_Interpret%20multiple%20regression%20results%20with%20Python.ipynb): Introducing multiple linear regression, this project explores relationships between sales and multiple marketing variables, demonstrating model building and interpretation for multi-variable scenarios.
       
         + [Project_07_Perform multiple linear regression_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_07_Perform%20multiple%20linear%20regression_Part1.ipynb): This project involves performing multiple regression to estimate sales based on combined TV, social media, radio, and influencer promotions. It includes data exploration, model fitting, and insight communication.
       
         + [Project_08_Perform multiple linear regression_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_08_Perform%20multiple%20linear%20regression_Part2.ipynb): A continuation of multiple regression, this part enhances skills in multi-variable analysis and deepens the interpretation of regression outputs for business recommendations.
       
         + [Project_09_ Explore one-way versus two-way ANOVA tests with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_09_%20Explore%20one-way%20versus%20two-way%20ANOVA%20tests%20with%20Python.ipynb): This project covers one-way and two-way ANOVA tests, using Python to compare means across multiple groups, with applications in marketing data to test for significant differences.
        
         + [Project_10_Hypothesis testing with Python_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_10_Hypothesis%20testing%20with%20Python_Part1.ipynb): This notebook applies hypothesis testing, particularly one-way ANOVA, to determine significant differences in sales across marketing promotion types, aiding stakeholders in strategic planning.
       
         + [Project_11_Hypothesis testing with Python_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_11_Hypothesis%20testing%20with%20Python_Part2.ipynb): This project expands on ANOVA hypothesis testing, including post hoc tests to analyze differences in sales among various marketing promotion types. It provides a structured approach to model assumptions, ANOVA testing, and communicating results to stakeholders.
       
         + [Project_12_Construct a logistic regression model with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_12_Construct%20a%20logistic%20regression%20model%20with%20Python.ipynb): This project introduces binomial logistic regression, covering model construction and evaluation. It explores applications in customer satisfaction analysis, using logistic regression to predict satisfaction based on flight data.
       
         + [Project_13_Perform logistic regression_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_13_Perform%20logistic%20regression_Part1.ipynb): This project applies binomial logistic regression for an airline, analyzing customer satisfaction based on in-flight experience. It includes exploratory data analysis (EDA), model creation, and evaluation using a confusion matrix.
       
         + [Project_14_Perform logistic regression_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_14_Perform%20logistic%20regression_Part2.ipynb):
       
         + [Project_15_Automatidata_part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_15_Automatidata_part1.ipynb):
       
         + [Project_16_Automatidata_part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_16_Automatidata_part2.ipynb):
       
         + [Project_17_TikTok_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_17_TikTok_Part1.ipynb): Part of a larger TikTok project, this notebook uses logistic regression to predict verified user status, analyzing relationships between video characteristics and user verification. The insights aim to support a model predicting content type as a claim or opinion.
       
         + [Project_18_TikTok_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_18_TikTok_Part2.ipynb): A continuation of the TikTok logistic regression project, this part delves deeper into model evaluation and interpretation, providing recommendations based on verified status predictions to enhance content review efficiency.
       
         + [Project_19_Waze_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_19_Waze_Part1.ipynb):
       
         + [Project_20_Waze_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/04%20-%20Regression-Analysis-Simplify-Complex-Data-Relationships/Project_20_Waze_Part2.ipynb):

      + [The-Nuts-and-Bolts-of-Machine-Learning](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning):
    
         + [Project_01_Build an XGBoost model_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_01_Build%20an%20XGBoost%20model_Part1.ipynb):
       
         + [Project_02_Build an XGBoost model_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_02_Build%20an%20XGBoost%20model_Part2.ipynb):
       
         + [Project_03_Automatidata](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_03_Automatidata.ipynb):
       
         + [Project_04_TikTok_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_04_TikTok_Part1.ipynb):
       
         + [Project_05_TikTok_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_05_TikTok_Part2.ipynb):
       
         + [Project_06_Waze_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_06_Waze_Part1.ipynb):
       
         + [Project_07_Waze_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_07_Waze_Part2.ipynb):
       
         + [Project_08_Feature engineering with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_08_Feature%20engineering%20with%20Python.ipynb):
       
         + [Project_09_Perform feature engineering_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_09_Perform%20feature%20engineering_Part1.ipynb):
       
         + [Project_10_Perform feature engineering_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_10_Perform%20feature%20engineering_Part2.ipynb):
       
         + [Project_11_Construct a Naive Bayes model with Python](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_11_Construct%20a%20Naive%20Bayes%20model%20with%20Python.ipynb):
       
         + [Project_12_Build a Naive Bayes model_Part1](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_12_Build%20a%20Naive%20Bayes%20model_Part1.ipynb):
       
         + [Project_13_Build a Naive Bayes model_Part2](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/blob/main/Coursera-Projects/05%20-%20Google-Advanced-Data-Analytics-Professional-Certificate/05%20-%20The-Nuts-and-Bolts-of-Machine-Learning/Project_13_Build%20a%20Naive%20Bayes%20model_Part2.ipynb):
      
Each folder contains assignments, practical projects, and case studies from the respective certifications, offering a detailed look at my learning process and practical applications.

________________________________________


**[4. Data-Science-Projects](https://github.com/Waliid18/Walid-Lahlali-Data-Science-Portfolio/tree/main/Data-Science-Projects)**

This branch showcases independent data science projects I’ve worked on, organized into **six** key categories:

   + [Data-Visualization-Projects](): Projects focused on creating compelling data visualizations to uncover insights.
   + [Exploratory-Data-Analysis-EDA-Projects](): Detailed EDA projects that analyze datasets and uncover trends.
   + [Machine-Learning-Projects](): Machine learning projects ranging from regression and classification to clustering.
   + [Natural-Language-Processing-NLP-Projects](): Projects focused on NLP techniques such as text classification and sentiment analysis.
   + [Deep-Learning-Projects](): Projects exploring deep learning techniques, including neural networks and CNNs.
   + [Time-Series-Analysis-Projects](): Time series analysis and forecasting projects using techniques like ARIMA and LSTM.
     
Each folder contains detailed projects showcasing my ability to apply machine learning, deep learning, and data analysis techniques to real-world data science challenges.

________________________________________

## How to Navigate

   + **Branches and Leaves**: Each folder (branch) contains subdirectories (branches) and project notebooks (leaves) that represent individual topics, projects, or assignments.
   + **Notebooks**: Every notebook includes thorough explanations, comments, and code that can be easily followed and reproduced.

________________________________________

## Why This Portfolio?

This portfolio is a reflection of my **journey** as a **data scientist**. Each project demonstrates my **expertise** across a range of topics, from **`data wrangling`** and **`statistical analysis`** to **`machine learning`**, **`deep learning`** and advanced **`data visualization`**. It’s designed to offer a structured, comprehensive view of my technical **skills** and analytical approach, combining both foundational principles and advanced techniques.

________________________________________

## Key Skills

+ **Data Wrangling and Cleaning**: Advanced manipulation using `Pandas`, ensuring datasets are organized, clean, and ready for analysis or model development.
  
+ **Statistical Analysis and Hypothesis Testing**: Rigorous statistical methodologies to uncover insights, validate findings, and support data-driven decision-making.
  
+ **Machine Learning and Predictive Modeling**: Proven experience in building and optimizing models, from `regression` and `classification` to `clustering`, using `scikit-learn` and `deep learning` frameworks.
  
+ **Deep Learning and NLP**: Proficiency in neural networks (`CNNs` for image analysis and `NLP` for text processing), enabling nuanced and effective solutions for complex data.
  
+ **Data Visualization and Storytelling**: Leveraging `Matplotlib`, `Seaborn`, and `Tableau` to create clear, insightful visualizations that transform complex data into accessible, meaningful narratives.

________________________________________
  
## Tools and Technologies

Below are some key tools I leverage across projects to achieve high-quality, efficient results:

+ **Languages and Libraries**: `Python` (`Pandas`, `NumPy`, `Scikit-learn`, `TensorFlow`, `PyTorch`), `SQL`
  
+ **Development Environments**: `Jupyter Notebook`, `Visual Studio Code`
  
+ **Data Visualization and Reporting**: `Matplotlib`, `Seaborn`, `Tableau`
  
+ **Collaboration and Deployment**: `Git`, `GitHub`, `Streamlit`
  
Whether you’re a recruiter looking for a well-rounded candidate or a fellow data scientist seeking inspiration, this portfolio is crafted to provide a clear and organized view of my skills and achievements. Feel free to explore the repository, clone the projects, and reach out if you’d like to discuss further!

________________________________________

## Contact


